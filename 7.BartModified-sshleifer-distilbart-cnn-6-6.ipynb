{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "import copy\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0e4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"sshleifer/distilbart-cnn-6-6\"\n",
    "batch_size = 2\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d823f557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b6e3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 11:24:57 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  A100-PCIE-40GB      Off  | 00000000:01:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    39W / 250W |   7082MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  A100-PCIE-40GB      Off  | 00000000:41:00.0 Off |                    0 |\r\n",
      "| N/A   67C    P0   234W / 250W |  40137MiB / 40536MiB |     96%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  A100-PCIE-40GB      Off  | 00000000:81:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  A100-PCIE-40GB      Off  | 00000000:C1:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  A100-PCIE-40GB      Off  | 00000000:E1:00.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    39W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A    914655      C   .../obj_detection/bin/python     5979MiB |\r\n",
      "|    0   N/A  N/A   2026001      C   python                            603MiB |\r\n",
      "|    0   N/A  N/A   2839719      C   python                            497MiB |\r\n",
      "|    1   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    1   N/A  N/A   3404078      C   python                          39551MiB |\r\n",
      "|    2   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    3   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    4   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9147b647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a13d8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c9537f852843a7a2ec607b2ce7d9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb7f9ec91c54926bf6c93a1bf3de5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88cce9b6365462ea83143965e14bab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54620b1d7d2461c90c297600ae754fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f009ba6612d4f4eafa9c3b33eb33926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the function\n",
    "def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "    \"\"\"\n",
    "    Shift input ids one token to the right.\n",
    "    \"\"\"\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "\n",
    "    if pad_token_id is None:\n",
    "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    return shifted_input_ids\n",
    "\n",
    "\n",
    "# define the class\n",
    "class MLT(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_checkpoint):\n",
    "      super(MLT, self).__init__()\n",
    "\n",
    "      self.model = BartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "      self.encoder = self.model.get_encoder()\n",
    "\n",
    "      self.decoder1 = self.model.get_decoder()\n",
    "      self.decoder2 = copy.deepcopy(self.decoder1)\n",
    "\n",
    "      self.lm_head1 = self.model.get_output_embeddings()\n",
    "      self.lm_head2 = copy.deepcopy(self.lm_head1)\n",
    "\n",
    "    def get_config(self):\n",
    "      return self.model.config\n",
    "\n",
    "    def get_decoder(self):\n",
    "      return self.decoder1\n",
    "\n",
    "    def get_lm_head(self):\n",
    "      return self.lm_head1\n",
    "\n",
    "    def get_final_logits_bias(self):\n",
    "      return self.model.final_logits_bias\n",
    "\n",
    "    def get_tokenizer(self):\n",
    "      return self.tokenizer\n",
    "\n",
    "    def forward(self, text, summary1, summary2):\n",
    "      # inputs = self.tokenizer.encode(text, return_tensors=\"pt\")\n",
    "      # target1 = self.tokenizer.encode(summary1, return_tensors=\"pt\")\n",
    "      # target2 = self.tokenizer.encode(summary2, return_tensors=\"pt\")\n",
    "\n",
    "      inputs = text\n",
    "      target1 = summary1\n",
    "      target2 = summary2\n",
    "\n",
    "      encoder_outputs = self.encoder(inputs)\n",
    "\n",
    "      decoder_input_ids1 = shift_tokens_right(\n",
    "                    target1, self.model.config.pad_token_id, self.model.config.decoder_start_token_id\n",
    "                )\n",
    "      \n",
    "      decoder_input_ids2 = shift_tokens_right(\n",
    "                    target2, self.model.config.pad_token_id, self.model.config.decoder_start_token_id\n",
    "                )\n",
    "      \n",
    "      \n",
    "      decoder_outputs1 = self.decoder1(\n",
    "          decoder_input_ids1, \n",
    "          encoder_hidden_states=encoder_outputs[0], \n",
    "          use_cache = False,\n",
    "          output_attentions=self.model.config.output_attentions,\n",
    "          output_hidden_states=self.model.config.output_hidden_states,\n",
    "          return_dict=self.model.config.use_return_dict,\n",
    "          ) \n",
    "\n",
    "      decoder_outputs2 = self.decoder2(\n",
    "          decoder_input_ids2, \n",
    "          encoder_hidden_states=encoder_outputs[0], \n",
    "          use_cache = False,\n",
    "          output_attentions=self.model.config.output_attentions,\n",
    "          output_hidden_states=self.model.config.output_hidden_states,\n",
    "          return_dict=self.model.config.use_return_dict,\n",
    "          )  \n",
    "\n",
    "      lm_logits1 = self.lm_head1(decoder_outputs1[0]) + self.model.final_logits_bias\n",
    "      lm_logits2 = self.lm_head2(decoder_outputs2[0]) + self.model.final_logits_bias   \n",
    "\n",
    "      masked_lm_loss1 = None\n",
    "      masked_lm_loss2 = None\n",
    "      loss_fct = CrossEntropyLoss()\n",
    "      masked_lm_loss1 = loss_fct(lm_logits1.view(-1, self.model.config.vocab_size), target1.view(-1))\n",
    "      masked_lm_loss2 = loss_fct(lm_logits2.view(-1, self.model.config.vocab_size), target2.view(-1))\n",
    "      \n",
    "      # return {\n",
    "      #     'loss1': masked_lm_loss1, \n",
    "      #     'loss2': masked_lm_loss2,\n",
    "      #     'encoder_outputs': encoder_outputs\n",
    "      #     }\n",
    "\n",
    "      return (masked_lm_loss1, masked_lm_loss2, encoder_outputs)\n",
    "\n",
    "\n",
    "# create the object\n",
    "model = MLT(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27590c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLT(\n",
       "  (model): BartForConditionalGeneration(\n",
       "    (model): BartModel(\n",
       "      (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       "  )\n",
       "  (encoder): BartEncoder(\n",
       "    (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder1): BartDecoder(\n",
       "    (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder2): BartDecoder(\n",
       "    (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head1): Linear(in_features=1024, out_features=50264, bias=False)\n",
       "  (lm_head2): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc85895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "137\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "transcripts_dir = Path(\"./data/ami/transcripts\")\n",
    "abs_summaries_dir = Path(\"./data/ami/summaries/abstractive\")\n",
    "ext_summaries_dir = Path(\"./data/ami/summaries/extractive\")\n",
    "\n",
    "transcripts = []\n",
    "abs_summaries = []\n",
    "ext_summaries = []\n",
    "\n",
    "for file in transcripts_dir.iterdir():\n",
    "  transcripts.append(file.read_text())\n",
    "\n",
    "for file in abs_summaries_dir.iterdir():\n",
    "  abs_summaries.append(file.read_text())\n",
    "\n",
    "for file in ext_summaries_dir.iterdir():\n",
    "  ext_summaries.append(file.read_text())\n",
    "\n",
    "print(len(transcripts))\n",
    "print(len(abs_summaries))\n",
    "print(len(ext_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58b2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_transcripts, val_transcripts, train_abs_summaries, val_abs_summaries = train_test_split(transcripts, abs_summaries, test_size=.2)\n",
    "_, _, train_ext_summaries, val_ext_summaries = train_test_split(transcripts, ext_summaries, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0016b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_transcripts_encodings = tokenizer(train_transcripts, truncation=True, padding=True)\n",
    "val_transcripts_encodings = tokenizer(val_transcripts, truncation=True, padding=True)\n",
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "  train_abs_summaries_encodings = tokenizer(train_abs_summaries, truncation=True, padding=True)\n",
    "  val_abs_summaries_encodings = tokenizer(val_abs_summaries, truncation=True, padding=True)\n",
    "\n",
    "  train_ext_summaries_encodings = tokenizer(train_ext_summaries, truncation=True, padding=True)\n",
    "  val_ext_summaries_encodings = tokenizer(val_ext_summaries, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0e2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transcripts, abs_summaries, ext_summaries):\n",
    "        self.transcripts = transcripts\n",
    "        self.abs_summaries = abs_summaries\n",
    "        self.ext_summaries = ext_summaries\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.transcripts.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.transcripts.items()}\n",
    "        item[\"abs\"] = torch.tensor(self.abs_summaries[\"input_ids\"][idx])\n",
    "        item[\"ext\"] = torch.tensor(self.ext_summaries[\"input_ids\"][idx])\n",
    "        return item\n",
    "\n",
    "    \n",
    "\n",
    "train_dataset = MeetDataset(train_transcripts_encodings, train_abs_summaries_encodings, train_ext_summaries_encodings)\n",
    "val_dataset = MeetDataset(val_transcripts_encodings, val_abs_summaries_encodings, val_ext_summaries_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2175d04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__(), val_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f20ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f49d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartPretrainedModel\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "class DecoderForGeneration(BartPretrainedModel):\n",
    "\n",
    "    def __init__(self, config, decoder, lm_head, final_logits_bias):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.config = config\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "        self.final_logits_bias = final_logits_bias\n",
    "\n",
    "    # def get_encoder(self):\n",
    "    #     return self.get_encoder()\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.model.get_decoder()\n",
    "\n",
    "    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
    "        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n",
    "        self._resize_final_logits_bias(new_num_tokens)\n",
    "        return new_embeddings\n",
    "\n",
    "    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n",
    "        old_num_tokens = self.final_logits_bias.shape[-1]\n",
    "        if new_num_tokens <= old_num_tokens:\n",
    "            new_bias = self.final_logits_bias[:, :new_num_tokens]\n",
    "        else:\n",
    "            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n",
    "            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n",
    "        self.register_buffer(\"final_logits_bias\", new_bias)\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head = new_embeddings\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        decoder_input_ids=None,\n",
    "        decoder_attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        past_key_values=None,\n",
    "        inputs_embeds=None,\n",
    "        decoder_inputs_embeds=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if labels is not None:\n",
    "            # if use_cache:\n",
    "            #     logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n",
    "            use_cache = False\n",
    "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "                decoder_input_ids = shift_tokens_right(\n",
    "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "                )\n",
    "\n",
    "        decoder_outputs = self.decoder(\n",
    "        decoder_input_ids, \n",
    "        encoder_hidden_states=encoder_outputs[0], \n",
    "        use_cache = False,\n",
    "        output_attentions=self.config.output_attentions,\n",
    "        output_hidden_states=self.config.output_hidden_states,\n",
    "        return_dict=self.config.use_return_dict,\n",
    "        )\n",
    "        lm_logits = self.lm_head(decoder_outputs[0]) + self.final_logits_bias\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(lm_logits.view(-1, model.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + decoder_outputs[1:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "        self,\n",
    "        decoder_input_ids,\n",
    "        past=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        use_cache=None,\n",
    "        encoder_outputs=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # cut decoder_input_ids if past is used\n",
    "        if past is not None:\n",
    "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "            \"past_key_values\": past,\n",
    "            \"decoder_input_ids\": decoder_input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"head_mask\": head_mask,\n",
    "            \"decoder_head_mask\": decoder_head_mask,\n",
    "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
    "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
    "        }\n",
    "\n",
    "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
    "        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def _reorder_cache(past, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past:\n",
    "            # cached cross_attention states don't have to be reordered -> they are always the same\n",
    "            reordered_past += (\n",
    "                tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
    "            )\n",
    "        return reordered_past\n",
    "\n",
    "\n",
    "myDecoderModel = DecoderForGeneration(model.get_config(), model.get_decoder(), model.get_lm_head(), model.get_final_logits_bias())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec54ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderForGeneration(\n",
       "  (decoder): BartDecoder(\n",
       "    (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDecoderModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e5dd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4284777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2959250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tanik_1821cs08/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "19.519981384277344\n",
      "17.222017288208008\n",
      "12.43929672241211\n",
      "7.167011737823486\n",
      "7.189304828643799\n",
      "7.056176662445068\n",
      "6.782205104827881\n",
      "8.063051223754883\n",
      "6.272757530212402\n",
      "6.380002021789551\n",
      "5.949895858764648\n",
      "6.2204132080078125\n",
      "5.901455879211426\n",
      "6.121360778808594\n",
      "7.088442802429199\n",
      "6.144237995147705\n",
      "5.452024459838867\n",
      "5.6802568435668945\n",
      "6.905918121337891\n",
      "5.670199394226074\n",
      "5.726774215698242\n",
      "5.741528511047363\n",
      "6.162428379058838\n",
      "5.891425132751465\n",
      "5.280479431152344\n",
      "5.561770439147949\n",
      "6.028838157653809\n",
      "5.667051315307617\n",
      "5.75628662109375\n",
      "7.533000469207764\n",
      "5.732135772705078\n",
      "4.897229194641113\n",
      "5.484233856201172\n",
      "5.772734642028809\n",
      "5.819028377532959\n",
      "5.706168174743652\n",
      "5.593053817749023\n",
      "5.573624134063721\n",
      "6.150084495544434\n",
      "5.651205062866211\n",
      "4.886440277099609\n",
      "5.389982223510742\n",
      "5.547189712524414\n",
      "5.440338134765625\n",
      "4.130610466003418\n",
      "4.814149379730225\n",
      "5.608158588409424\n",
      "5.381970405578613\n",
      "5.309983730316162\n",
      "5.230558395385742\n",
      "5.5060834884643555\n",
      "4.583771705627441\n",
      "5.918322563171387\n",
      "5.573178291320801\n",
      "5.0798139572143555\n",
      "Validation\n",
      "5.048595428466797\n",
      "6.617425441741943\n",
      "6.715695381164551\n",
      "7.217486381530762\n",
      "5.885069847106934\n",
      "7.731260299682617\n",
      "7.344021797180176\n",
      "8.393804550170898\n",
      "7.713949203491211\n",
      "7.989794731140137\n",
      "7.194854736328125\n",
      "6.9272918701171875\n",
      "6.837182998657227\n",
      "7.061860084533691\n",
      "1\n",
      "5.580229759216309\n",
      "5.2910075187683105\n",
      "5.601799011230469\n",
      "5.758423805236816\n",
      "5.176408290863037\n",
      "4.4581522941589355\n",
      "5.255302906036377\n",
      "3.5563385486602783\n",
      "5.248997688293457\n",
      "3.7515316009521484\n",
      "5.481715202331543\n",
      "5.434885025024414\n",
      "5.186206817626953\n",
      "5.568853855133057\n",
      "5.3850507736206055\n",
      "5.3757100105285645\n",
      "4.451557636260986\n",
      "5.632646083831787\n",
      "5.251883506774902\n",
      "5.587782859802246\n",
      "4.923419952392578\n",
      "4.791097164154053\n",
      "5.171415328979492\n",
      "5.384330749511719\n",
      "5.617992877960205\n",
      "4.981753349304199\n",
      "5.727492809295654\n",
      "4.95153284072876\n",
      "4.961673736572266\n",
      "4.696802616119385\n",
      "5.165971279144287\n",
      "5.34013557434082\n",
      "5.465806484222412\n",
      "5.092031478881836\n",
      "5.298700332641602\n",
      "5.043940544128418\n",
      "4.752375602722168\n",
      "5.083922863006592\n",
      "3.8134052753448486\n",
      "3.9437026977539062\n",
      "5.180373191833496\n",
      "7.102451324462891\n",
      "5.376540184020996\n",
      "4.667901992797852\n",
      "4.695860385894775\n",
      "5.000132083892822\n",
      "5.293151378631592\n",
      "4.937338829040527\n",
      "5.111334800720215\n",
      "5.384377479553223\n",
      "4.653887748718262\n",
      "5.634918689727783\n",
      "4.939826965332031\n",
      "4.6966071128845215\n",
      "5.4716410636901855\n",
      "Validation\n",
      "4.758735656738281\n",
      "6.255463123321533\n",
      "6.30611515045166\n",
      "6.866243362426758\n",
      "5.645795822143555\n",
      "7.3851423263549805\n",
      "6.943070888519287\n",
      "8.00911808013916\n",
      "7.2530670166015625\n",
      "7.609023094177246\n",
      "6.8273115158081055\n",
      "6.542993068695068\n",
      "6.4651079177856445\n",
      "6.603987693786621\n",
      "2\n",
      "4.97072696685791\n",
      "4.852900505065918\n",
      "5.390471458435059\n",
      "5.228504180908203\n",
      "4.7375078201293945\n",
      "6.621124267578125\n",
      "4.88249397277832\n",
      "4.925695896148682\n",
      "4.8346781730651855\n",
      "4.557399749755859\n",
      "4.775880336761475\n",
      "5.299740791320801\n",
      "4.943383693695068\n",
      "4.8213582038879395\n",
      "4.862452030181885\n",
      "5.245785713195801\n",
      "5.084418296813965\n",
      "5.069334983825684\n",
      "5.101074695587158\n",
      "4.498386383056641\n",
      "4.795393943786621\n",
      "5.029240608215332\n",
      "5.089962005615234\n",
      "5.437019348144531\n",
      "4.792086124420166\n",
      "4.835760593414307\n",
      "5.092785835266113\n",
      "4.610881805419922\n",
      "4.501073837280273\n",
      "5.115540504455566\n",
      "5.224839210510254\n",
      "4.997470378875732\n",
      "4.817929267883301\n",
      "4.609870433807373\n",
      "4.777148723602295\n",
      "5.136483669281006\n",
      "4.762529373168945\n",
      "5.390923500061035\n",
      "4.917381286621094\n",
      "4.748683929443359\n",
      "5.2248029708862305\n",
      "5.003630638122559\n",
      "4.353729248046875\n",
      "4.233648777008057\n",
      "4.218603610992432\n",
      "3.3093886375427246\n",
      "4.541723251342773\n",
      "4.99789571762085\n",
      "5.093360900878906\n",
      "4.970279693603516\n",
      "5.375859260559082\n",
      "3.374929428100586\n",
      "5.283895015716553\n",
      "4.473781108856201\n",
      "4.458780765533447\n",
      "Validation\n",
      "4.541501522064209\n",
      "6.013256072998047\n",
      "6.018442153930664\n",
      "6.614099502563477\n",
      "5.411648273468018\n",
      "7.077303886413574\n",
      "6.667342662811279\n",
      "7.735787391662598\n",
      "6.998021125793457\n",
      "7.347920894622803\n",
      "6.602466583251953\n",
      "6.286210060119629\n",
      "6.207332611083984\n",
      "6.336253643035889\n",
      "3\n",
      "4.970674991607666\n",
      "4.345589637756348\n",
      "5.00369119644165\n",
      "4.423504829406738\n",
      "3.4359123706817627\n",
      "4.669498920440674\n",
      "4.682152271270752\n",
      "4.760070323944092\n",
      "4.103801727294922\n",
      "4.66798734664917\n",
      "4.755076885223389\n",
      "3.175290584564209\n",
      "4.548581600189209\n",
      "4.88034725189209\n",
      "4.885873317718506\n",
      "4.994266033172607\n",
      "4.7891011238098145\n",
      "4.101428985595703\n",
      "4.907924652099609\n",
      "5.170499801635742\n",
      "5.04897403717041\n",
      "4.94901180267334\n",
      "5.083774566650391\n",
      "5.166772842407227\n",
      "5.342451572418213\n",
      "5.240860462188721\n",
      "5.037062168121338\n",
      "5.036547660827637\n",
      "4.805722236633301\n",
      "4.427197456359863\n",
      "5.045741081237793\n",
      "4.127780914306641\n",
      "4.998361110687256\n",
      "4.845548629760742\n",
      "5.067809581756592\n",
      "4.948992729187012\n",
      "4.295205116271973\n",
      "6.689549446105957\n",
      "4.0009589195251465\n",
      "5.2175188064575195\n",
      "5.024398326873779\n",
      "4.692743301391602\n",
      "4.51789665222168\n",
      "5.000727653503418\n",
      "4.332242965698242\n",
      "4.236568927764893\n",
      "4.57147741317749\n",
      "4.7683024406433105\n",
      "5.193181991577148\n",
      "4.995254993438721\n",
      "5.073843955993652\n",
      "4.262388706207275\n",
      "3.882307529449463\n",
      "4.954665184020996\n",
      "5.161722660064697\n",
      "Validation\n",
      "4.445967197418213\n",
      "5.9015703201293945\n",
      "5.871945858001709\n",
      "6.5075178146362305\n",
      "5.26874303817749\n",
      "6.929640769958496\n",
      "6.557165145874023\n",
      "7.520207405090332\n",
      "6.8238983154296875\n",
      "7.196131229400635\n",
      "6.4752655029296875\n",
      "6.156309127807617\n",
      "6.076760292053223\n",
      "6.216336727142334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "def train(model, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss': [], 'validation_loss': []}  \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        # model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data['input_ids'], data['abs'], data['ext'] = data['input_ids'].to(device), data['abs'].to(device), data['ext'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data['input_ids'], data['abs'], data['ext'])\n",
    "            loss = output[0] + output[1]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.item())\n",
    "            print(loss.item())\n",
    "\n",
    "        print(\"Validation\")\n",
    "        model.eval()\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            with torch.no_grad():\n",
    "              data['input_ids'], data['abs'], data['ext'] = data['input_ids'].to(device), data['abs'].to(device), data['ext'].to(device)\n",
    "              output = model(data['input_ids'], data['abs'], data['ext'])\n",
    "              loss = output[0] + output[1]\n",
    "              useful_stuff['validation_loss'].append(loss.item())\n",
    "              print(loss.item())\n",
    "\n",
    "              predictions = myDecoderModel.generate(data['input_ids'], encoder_outputs=output[2])\n",
    "              labels = data['abs'].cpu()\n",
    "\n",
    "              decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "              # Replace -100 in the labels as we can't decode them.\n",
    "              labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "              decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "              \n",
    "              # Rouge expects a newline after each sentence\n",
    "              decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "              decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "              metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "              \n",
    "        result = metric.compute(use_stemmer=True)\n",
    "        # Extract a few results from ROUGE\n",
    "        result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "    \n",
    "    return (useful_stuff, result)\n",
    "\n",
    "training_results = train(model, train_loader, validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a1e396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6b746aaf70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_results[0]['training_loss'], label=\"train\")\n",
    "plt.plot(training_results[0]['validation_loss'], label=\"val\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()\n",
    "#plt.title('training loss iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fdad87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 42.4731, 'rouge2': 16.1946, 'rougeL': 25.3606, 'rougeLsum': 40.4275}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d44fd335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 11:29:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-PCIE-40GB      Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    38W / 250W |   7082MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  A100-PCIE-40GB      Off  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   65C    P0   246W / 250W |  40137MiB / 40536MiB |     97%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  A100-PCIE-40GB      Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    36W / 250W |    586MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  A100-PCIE-40GB      Off  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    36W / 250W |    586MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  A100-PCIE-40GB      Off  | 00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   55C    P0    77W / 250W |  17267MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    914655      C   .../obj_detection/bin/python     5979MiB |\n",
      "|    0   N/A  N/A   2026001      C   python                            603MiB |\n",
      "|    0   N/A  N/A   2839719      C   python                            497MiB |\n",
      "|    1   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    1   N/A  N/A   3404078      C   python                          39551MiB |\n",
      "|    2   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    3   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    4   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    4   N/A  N/A   1866800      C   ...onda3/envs/sb3/bin/python    16681MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46700e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sshleifer-distilbart-cnn-6-6.pickle', 'wb') as f:\n",
    "    pickle.dump(training_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e175b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
