{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "import copy\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0e4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-base\"\n",
    "batch_size = 2\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d823f557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b6e3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 11:31:30 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  A100-PCIE-40GB      Off  | 00000000:01:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    38W / 250W |   7082MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  A100-PCIE-40GB      Off  | 00000000:41:00.0 Off |                    0 |\r\n",
      "| N/A   70C    P0   264W / 250W |  40137MiB / 40536MiB |    100%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  A100-PCIE-40GB      Off  | 00000000:81:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  A100-PCIE-40GB      Off  | 00000000:C1:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  A100-PCIE-40GB      Off  | 00000000:E1:00.0 Off |                    0 |\r\n",
      "| N/A   38C    P0    40W / 250W |  17267MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A    914655      C   .../obj_detection/bin/python     5979MiB |\r\n",
      "|    0   N/A  N/A   2026001      C   python                            603MiB |\r\n",
      "|    0   N/A  N/A   2839719      C   python                            497MiB |\r\n",
      "|    1   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    1   N/A  N/A   3404078      C   python                          39551MiB |\r\n",
      "|    2   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    3   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    4   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    4   N/A  N/A   1866800      C   ...onda3/envs/sb3/bin/python    16681MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9147b647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a13d8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1450c196a8fa414d8166a9486c36b587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b7b77e53b74e5dabb117432ab0d3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537d0f424fb646bdad2e47ebb8b72ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f6fb98835a4c9e96f53f8c3b766ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb24c4fd36c4ea481ac18bc689f947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the function\n",
    "def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "    \"\"\"\n",
    "    Shift input ids one token to the right.\n",
    "    \"\"\"\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "\n",
    "    if pad_token_id is None:\n",
    "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    return shifted_input_ids\n",
    "\n",
    "\n",
    "# define the class\n",
    "class MLT(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_checkpoint):\n",
    "      super(MLT, self).__init__()\n",
    "\n",
    "      self.model = BartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "      self.encoder = self.model.get_encoder()\n",
    "\n",
    "      self.decoder1 = self.model.get_decoder()\n",
    "      self.decoder2 = copy.deepcopy(self.decoder1)\n",
    "\n",
    "      self.lm_head1 = self.model.get_output_embeddings()\n",
    "      self.lm_head2 = copy.deepcopy(self.lm_head1)\n",
    "\n",
    "    def get_config(self):\n",
    "      return self.model.config\n",
    "\n",
    "    def get_decoder(self):\n",
    "      return self.decoder1\n",
    "\n",
    "    def get_lm_head(self):\n",
    "      return self.lm_head1\n",
    "\n",
    "    def get_final_logits_bias(self):\n",
    "      return self.model.final_logits_bias\n",
    "\n",
    "    def get_tokenizer(self):\n",
    "      return self.tokenizer\n",
    "\n",
    "    def forward(self, text, summary1, summary2):\n",
    "      # inputs = self.tokenizer.encode(text, return_tensors=\"pt\")\n",
    "      # target1 = self.tokenizer.encode(summary1, return_tensors=\"pt\")\n",
    "      # target2 = self.tokenizer.encode(summary2, return_tensors=\"pt\")\n",
    "\n",
    "      inputs = text\n",
    "      target1 = summary1\n",
    "      target2 = summary2\n",
    "\n",
    "      encoder_outputs = self.encoder(inputs)\n",
    "\n",
    "      decoder_input_ids1 = shift_tokens_right(\n",
    "                    target1, self.model.config.pad_token_id, self.model.config.decoder_start_token_id\n",
    "                )\n",
    "      \n",
    "      decoder_input_ids2 = shift_tokens_right(\n",
    "                    target2, self.model.config.pad_token_id, self.model.config.decoder_start_token_id\n",
    "                )\n",
    "      \n",
    "      \n",
    "      decoder_outputs1 = self.decoder1(\n",
    "          decoder_input_ids1, \n",
    "          encoder_hidden_states=encoder_outputs[0], \n",
    "          use_cache = False,\n",
    "          output_attentions=self.model.config.output_attentions,\n",
    "          output_hidden_states=self.model.config.output_hidden_states,\n",
    "          return_dict=self.model.config.use_return_dict,\n",
    "          ) \n",
    "\n",
    "      decoder_outputs2 = self.decoder2(\n",
    "          decoder_input_ids2, \n",
    "          encoder_hidden_states=encoder_outputs[0], \n",
    "          use_cache = False,\n",
    "          output_attentions=self.model.config.output_attentions,\n",
    "          output_hidden_states=self.model.config.output_hidden_states,\n",
    "          return_dict=self.model.config.use_return_dict,\n",
    "          )  \n",
    "\n",
    "      lm_logits1 = self.lm_head1(decoder_outputs1[0]) + self.model.final_logits_bias\n",
    "      lm_logits2 = self.lm_head2(decoder_outputs2[0]) + self.model.final_logits_bias   \n",
    "\n",
    "      masked_lm_loss1 = None\n",
    "      masked_lm_loss2 = None\n",
    "      loss_fct = CrossEntropyLoss()\n",
    "      masked_lm_loss1 = loss_fct(lm_logits1.view(-1, self.model.config.vocab_size), target1.view(-1))\n",
    "      masked_lm_loss2 = loss_fct(lm_logits2.view(-1, self.model.config.vocab_size), target2.view(-1))\n",
    "      \n",
    "      # return {\n",
    "      #     'loss1': masked_lm_loss1, \n",
    "      #     'loss2': masked_lm_loss2,\n",
    "      #     'encoder_outputs': encoder_outputs\n",
    "      #     }\n",
    "\n",
    "      return (masked_lm_loss1, masked_lm_loss2, encoder_outputs)\n",
    "\n",
    "\n",
    "# create the object\n",
    "model = MLT(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27590c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLT(\n",
       "  (model): BartForConditionalGeneration(\n",
       "    (model): BartModel(\n",
       "      (shared): Embedding(50265, 768, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  )\n",
       "  (encoder): BartEncoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder1): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder2): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head1): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lm_head2): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc85895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "137\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "transcripts_dir = Path(\"./data/ami/transcripts\")\n",
    "abs_summaries_dir = Path(\"./data/ami/summaries/abstractive\")\n",
    "ext_summaries_dir = Path(\"./data/ami/summaries/extractive\")\n",
    "\n",
    "transcripts = []\n",
    "abs_summaries = []\n",
    "ext_summaries = []\n",
    "\n",
    "for file in transcripts_dir.iterdir():\n",
    "  transcripts.append(file.read_text())\n",
    "\n",
    "for file in abs_summaries_dir.iterdir():\n",
    "  abs_summaries.append(file.read_text())\n",
    "\n",
    "for file in ext_summaries_dir.iterdir():\n",
    "  ext_summaries.append(file.read_text())\n",
    "\n",
    "print(len(transcripts))\n",
    "print(len(abs_summaries))\n",
    "print(len(ext_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58b2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_transcripts, val_transcripts, train_abs_summaries, val_abs_summaries = train_test_split(transcripts, abs_summaries, test_size=.2)\n",
    "_, _, train_ext_summaries, val_ext_summaries = train_test_split(transcripts, ext_summaries, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0016b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_transcripts_encodings = tokenizer(train_transcripts, truncation=True, padding=True)\n",
    "val_transcripts_encodings = tokenizer(val_transcripts, truncation=True, padding=True)\n",
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "  train_abs_summaries_encodings = tokenizer(train_abs_summaries, truncation=True, padding=True)\n",
    "  val_abs_summaries_encodings = tokenizer(val_abs_summaries, truncation=True, padding=True)\n",
    "\n",
    "  train_ext_summaries_encodings = tokenizer(train_ext_summaries, truncation=True, padding=True)\n",
    "  val_ext_summaries_encodings = tokenizer(val_ext_summaries, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0e2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transcripts, abs_summaries, ext_summaries):\n",
    "        self.transcripts = transcripts\n",
    "        self.abs_summaries = abs_summaries\n",
    "        self.ext_summaries = ext_summaries\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.transcripts.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.transcripts.items()}\n",
    "        item[\"abs\"] = torch.tensor(self.abs_summaries[\"input_ids\"][idx])\n",
    "        item[\"ext\"] = torch.tensor(self.ext_summaries[\"input_ids\"][idx])\n",
    "        return item\n",
    "\n",
    "    \n",
    "\n",
    "train_dataset = MeetDataset(train_transcripts_encodings, train_abs_summaries_encodings, train_ext_summaries_encodings)\n",
    "val_dataset = MeetDataset(val_transcripts_encodings, val_abs_summaries_encodings, val_ext_summaries_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2175d04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__(), val_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f20ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f49d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartPretrainedModel\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "class DecoderForGeneration(BartPretrainedModel):\n",
    "\n",
    "    def __init__(self, config, decoder, lm_head, final_logits_bias):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.config = config\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "        self.final_logits_bias = final_logits_bias\n",
    "\n",
    "    # def get_encoder(self):\n",
    "    #     return self.get_encoder()\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.model.get_decoder()\n",
    "\n",
    "    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
    "        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n",
    "        self._resize_final_logits_bias(new_num_tokens)\n",
    "        return new_embeddings\n",
    "\n",
    "    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n",
    "        old_num_tokens = self.final_logits_bias.shape[-1]\n",
    "        if new_num_tokens <= old_num_tokens:\n",
    "            new_bias = self.final_logits_bias[:, :new_num_tokens]\n",
    "        else:\n",
    "            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n",
    "            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n",
    "        self.register_buffer(\"final_logits_bias\", new_bias)\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head = new_embeddings\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        decoder_input_ids=None,\n",
    "        decoder_attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        past_key_values=None,\n",
    "        inputs_embeds=None,\n",
    "        decoder_inputs_embeds=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if labels is not None:\n",
    "            # if use_cache:\n",
    "            #     logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n",
    "            use_cache = False\n",
    "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "                decoder_input_ids = shift_tokens_right(\n",
    "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "                )\n",
    "\n",
    "        decoder_outputs = self.decoder(\n",
    "        decoder_input_ids, \n",
    "        encoder_hidden_states=encoder_outputs[0], \n",
    "        use_cache = False,\n",
    "        output_attentions=self.config.output_attentions,\n",
    "        output_hidden_states=self.config.output_hidden_states,\n",
    "        return_dict=self.config.use_return_dict,\n",
    "        )\n",
    "        lm_logits = self.lm_head(decoder_outputs[0]) + self.final_logits_bias\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(lm_logits.view(-1, model.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + decoder_outputs[1:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "        self,\n",
    "        decoder_input_ids,\n",
    "        past=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        use_cache=None,\n",
    "        encoder_outputs=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # cut decoder_input_ids if past is used\n",
    "        if past is not None:\n",
    "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "            \"past_key_values\": past,\n",
    "            \"decoder_input_ids\": decoder_input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"head_mask\": head_mask,\n",
    "            \"decoder_head_mask\": decoder_head_mask,\n",
    "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
    "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
    "        }\n",
    "\n",
    "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
    "        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def _reorder_cache(past, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past:\n",
    "            # cached cross_attention states don't have to be reordered -> they are always the same\n",
    "            reordered_past += (\n",
    "                tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
    "            )\n",
    "        return reordered_past\n",
    "\n",
    "\n",
    "myDecoderModel = DecoderForGeneration(model.get_config(), model.get_decoder(), model.get_lm_head(), model.get_final_logits_bias())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec54ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderForGeneration(\n",
       "  (decoder): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDecoderModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e5dd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4284777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2959250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tanik_1821cs08/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "18.882795333862305\n",
      "54.302276611328125\n",
      "19.361209869384766\n",
      "25.637006759643555\n",
      "13.483695983886719\n",
      "17.626834869384766\n",
      "14.205389976501465\n",
      "11.519613265991211\n",
      "11.34459114074707\n",
      "10.487491607666016\n",
      "10.92798900604248\n",
      "9.376659393310547\n",
      "10.056022644042969\n",
      "11.820122718811035\n",
      "10.33923625946045\n",
      "11.211187362670898\n",
      "10.68237590789795\n",
      "10.376569747924805\n",
      "10.19666576385498\n",
      "10.379863739013672\n",
      "9.485651969909668\n",
      "11.132145881652832\n",
      "10.029970169067383\n",
      "9.989851951599121\n",
      "10.369277000427246\n",
      "9.660463333129883\n",
      "10.271829605102539\n",
      "9.50216007232666\n",
      "10.838106155395508\n",
      "9.290691375732422\n",
      "8.794380187988281\n",
      "11.817346572875977\n",
      "9.647758483886719\n",
      "9.759505271911621\n",
      "9.998306274414062\n",
      "11.192092895507812\n",
      "10.189597129821777\n",
      "9.420242309570312\n",
      "9.061259269714355\n",
      "9.265241622924805\n",
      "8.931181907653809\n",
      "9.548059463500977\n",
      "8.456342697143555\n",
      "9.591245651245117\n",
      "9.708770751953125\n",
      "13.422983169555664\n",
      "12.35348129272461\n",
      "9.496381759643555\n",
      "9.195785522460938\n",
      "9.252885818481445\n",
      "9.00702953338623\n",
      "10.043864250183105\n",
      "8.847650527954102\n",
      "9.75437068939209\n",
      "10.168338775634766\n",
      "Validation\n",
      "13.253320693969727\n",
      "12.639060974121094\n",
      "11.43342399597168\n",
      "9.979363441467285\n",
      "14.322120666503906\n",
      "13.20506477355957\n",
      "11.75765609741211\n",
      "11.038330078125\n",
      "13.230524063110352\n",
      "13.332416534423828\n",
      "12.370894432067871\n",
      "11.894998550415039\n",
      "12.265487670898438\n",
      "11.270471572875977\n",
      "1\n",
      "9.09257984161377\n",
      "8.173920631408691\n",
      "9.078868865966797\n",
      "9.664727210998535\n",
      "9.108182907104492\n",
      "9.256609916687012\n",
      "8.91132926940918\n",
      "9.18293571472168\n",
      "9.335262298583984\n",
      "9.224189758300781\n",
      "8.501850128173828\n",
      "8.143365859985352\n",
      "8.565613746643066\n",
      "9.522281646728516\n",
      "9.86776351928711\n",
      "9.420014381408691\n",
      "9.247575759887695\n",
      "8.989962577819824\n",
      "9.107731819152832\n",
      "9.587440490722656\n",
      "8.71973991394043\n",
      "8.943411827087402\n",
      "8.688260078430176\n",
      "7.624286651611328\n",
      "8.860942840576172\n",
      "8.374464988708496\n",
      "9.074431419372559\n",
      "9.735048294067383\n",
      "8.59952163696289\n",
      "8.914251327514648\n",
      "7.638734817504883\n",
      "8.334614753723145\n",
      "8.202754020690918\n",
      "8.033369064331055\n",
      "9.793380737304688\n",
      "8.454534530639648\n",
      "11.757843017578125\n",
      "11.46621322631836\n",
      "9.7451171875\n",
      "8.788810729980469\n",
      "8.160734176635742\n",
      "9.890400886535645\n",
      "9.775641441345215\n",
      "8.653118133544922\n",
      "7.642162799835205\n",
      "9.201241493225098\n",
      "9.000076293945312\n",
      "9.819162368774414\n",
      "8.284884452819824\n",
      "10.297243118286133\n",
      "9.479873657226562\n",
      "9.276013374328613\n",
      "9.088370323181152\n",
      "9.124064445495605\n",
      "9.147274017333984\n",
      "Validation\n",
      "13.234825134277344\n",
      "12.56584644317627\n",
      "11.705957412719727\n",
      "10.041827201843262\n",
      "14.964876174926758\n",
      "13.615059852600098\n",
      "11.661138534545898\n",
      "11.22707748413086\n",
      "13.671602249145508\n",
      "13.75261402130127\n",
      "12.713600158691406\n",
      "12.214258193969727\n",
      "12.525655746459961\n",
      "11.465522766113281\n",
      "2\n",
      "9.031487464904785\n",
      "9.305668830871582\n",
      "9.26796817779541\n",
      "8.860538482666016\n",
      "8.963662147521973\n",
      "8.676349639892578\n",
      "8.962200164794922\n",
      "8.263212203979492\n",
      "8.165953636169434\n",
      "9.612977027893066\n",
      "9.306671142578125\n",
      "7.680902004241943\n",
      "8.990408897399902\n",
      "9.214110374450684\n",
      "8.056611061096191\n",
      "9.234807968139648\n",
      "7.996341228485107\n",
      "9.618762969970703\n",
      "9.8174467086792\n",
      "8.525733947753906\n",
      "8.44253158569336\n",
      "9.666153907775879\n",
      "8.974084854125977\n",
      "10.048507690429688\n",
      "8.914009094238281\n",
      "9.45457649230957\n",
      "9.219672203063965\n",
      "8.87338638305664\n",
      "8.331926345825195\n",
      "8.677131652832031\n",
      "8.822400093078613\n",
      "9.509269714355469\n",
      "7.560150146484375\n",
      "8.937732696533203\n",
      "9.125406265258789\n",
      "8.560644149780273\n",
      "11.007047653198242\n",
      "9.28094482421875\n",
      "9.821141242980957\n",
      "8.495002746582031\n",
      "8.377110481262207\n",
      "7.898322582244873\n",
      "9.545461654663086\n",
      "8.920915603637695\n",
      "8.115102767944336\n",
      "8.970685005187988\n",
      "8.640445709228516\n",
      "8.584304809570312\n",
      "8.956560134887695\n",
      "9.7067289352417\n",
      "8.447307586669922\n",
      "9.519492149353027\n",
      "8.791722297668457\n",
      "9.013652801513672\n",
      "8.784706115722656\n",
      "Validation\n",
      "12.534087181091309\n",
      "11.984676361083984\n",
      "11.497108459472656\n",
      "9.86728572845459\n",
      "14.709867477416992\n",
      "13.328954696655273\n",
      "11.209999084472656\n",
      "10.980097770690918\n",
      "13.381420135498047\n",
      "13.522064208984375\n",
      "12.467606544494629\n",
      "11.971996307373047\n",
      "12.292242050170898\n",
      "11.272895812988281\n",
      "3\n",
      "8.69420337677002\n",
      "9.414623260498047\n",
      "8.304360389709473\n",
      "8.447075843811035\n",
      "8.852561950683594\n",
      "7.384685516357422\n",
      "9.259268760681152\n",
      "9.0592041015625\n",
      "8.608447074890137\n",
      "8.398843765258789\n",
      "8.431131362915039\n",
      "8.786247253417969\n",
      "8.580424308776855\n",
      "8.334016799926758\n",
      "9.073487281799316\n",
      "8.804696083068848\n",
      "11.980716705322266\n",
      "10.728796005249023\n",
      "9.11855411529541\n",
      "8.640501022338867\n",
      "8.039604187011719\n",
      "8.894498825073242\n",
      "7.822629928588867\n",
      "9.213775634765625\n",
      "9.045156478881836\n",
      "9.022663116455078\n",
      "8.713468551635742\n",
      "8.900691986083984\n",
      "8.84066390991211\n",
      "9.282394409179688\n",
      "8.46060848236084\n",
      "8.932918548583984\n",
      "8.720295906066895\n",
      "8.93198299407959\n",
      "7.890275955200195\n",
      "9.483781814575195\n",
      "8.467893600463867\n",
      "8.419233322143555\n",
      "8.65578556060791\n",
      "8.092612266540527\n",
      "8.857439041137695\n",
      "8.840982437133789\n",
      "8.232210159301758\n",
      "8.939155578613281\n",
      "8.648058891296387\n",
      "9.263334274291992\n",
      "9.013137817382812\n",
      "8.784460067749023\n",
      "9.128852844238281\n",
      "8.374671936035156\n",
      "8.983781814575195\n",
      "8.265522003173828\n",
      "8.926362991333008\n",
      "8.866188049316406\n",
      "7.859355449676514\n",
      "Validation\n",
      "12.791109085083008\n",
      "12.153675079345703\n",
      "11.47049331665039\n",
      "9.83013916015625\n",
      "14.707077026367188\n",
      "13.278218269348145\n",
      "11.314969062805176\n",
      "10.950383186340332\n",
      "13.37681770324707\n",
      "13.508722305297852\n",
      "12.466501235961914\n",
      "11.95091438293457\n",
      "12.269390106201172\n",
      "11.258697509765625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "def train(model, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss': [], 'validation_loss': []}  \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        # model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data['input_ids'], data['abs'], data['ext'] = data['input_ids'].to(device), data['abs'].to(device), data['ext'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data['input_ids'], data['abs'], data['ext'])\n",
    "            loss = output[0] + output[1]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.item())\n",
    "            print(loss.item())\n",
    "\n",
    "        print(\"Validation\")\n",
    "        model.eval()\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            with torch.no_grad():\n",
    "              data['input_ids'], data['abs'], data['ext'] = data['input_ids'].to(device), data['abs'].to(device), data['ext'].to(device)\n",
    "              output = model(data['input_ids'], data['abs'], data['ext'])\n",
    "              loss = output[0] + output[1]\n",
    "              useful_stuff['validation_loss'].append(loss.item())\n",
    "              print(loss.item())\n",
    "\n",
    "              predictions = myDecoderModel.generate(data['input_ids'], encoder_outputs=output[2])\n",
    "              labels = data['abs'].cpu()\n",
    "\n",
    "              decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "              # Replace -100 in the labels as we can't decode them.\n",
    "              labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "              decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "              \n",
    "              # Rouge expects a newline after each sentence\n",
    "              decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "              decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "              metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "              \n",
    "        result = metric.compute(use_stemmer=True)\n",
    "        # Extract a few results from ROUGE\n",
    "        result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "    \n",
    "    return (useful_stuff, result)\n",
    "\n",
    "training_results = train(model, train_loader, validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a1e396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2f903ffca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_results[0]['training_loss'], label=\"train\")\n",
    "plt.plot(training_results[0]['validation_loss'], label=\"val\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()\n",
    "#plt.title('training loss iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fdad87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 3.9123, 'rouge2': 0.3966, 'rougeL': 3.8883, 'rougeLsum': 3.915}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d44fd335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 11:34:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-PCIE-40GB      Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    38W / 250W |   7082MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  A100-PCIE-40GB      Off  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   68C    P0   235W / 250W |  40137MiB / 40536MiB |     69%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  A100-PCIE-40GB      Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  A100-PCIE-40GB      Off  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  A100-PCIE-40GB      Off  | 00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    73W / 250W |  14099MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    914655      C   .../obj_detection/bin/python     5979MiB |\n",
      "|    0   N/A  N/A   2026001      C   python                            603MiB |\n",
      "|    0   N/A  N/A   2839719      C   python                            497MiB |\n",
      "|    1   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    1   N/A  N/A   3404078      C   python                          39551MiB |\n",
      "|    2   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    3   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    4   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    4   N/A  N/A   1869563      C   ...onda3/envs/sb3/bin/python    13513MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6948a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('facebook-bart-base.pickle', 'wb') as f:\n",
    "    pickle.dump(training_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46700e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
