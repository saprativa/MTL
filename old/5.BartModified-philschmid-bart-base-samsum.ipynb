{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "import copy\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0e4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"philschmid/bart-base-samsum\"\n",
    "batch_size = 2\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d823f557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b6e3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 11:20:29 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  A100-PCIE-40GB      Off  | 00000000:01:00.0 Off |                    0 |\r\n",
      "| N/A   35C    P0    76W / 250W |  39783MiB / 40536MiB |     38%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  A100-PCIE-40GB      Off  | 00000000:41:00.0 Off |                    0 |\r\n",
      "| N/A   68C    P0   241W / 250W |  40137MiB / 40536MiB |    100%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  A100-PCIE-40GB      Off  | 00000000:81:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    36W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  A100-PCIE-40GB      Off  | 00000000:C1:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  A100-PCIE-40GB      Off  | 00000000:E1:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    39W / 250W |    586MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A    914655      C   .../obj_detection/bin/python     5979MiB |\r\n",
      "|    0   N/A  N/A   1863611      C   python                          32701MiB |\r\n",
      "|    0   N/A  N/A   2026001      C   python                            603MiB |\r\n",
      "|    0   N/A  N/A   2839719      C   python                            497MiB |\r\n",
      "|    1   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    1   N/A  N/A   3404078      C   python                          39551MiB |\r\n",
      "|    2   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    3   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "|    4   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9147b647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a13d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function\n",
    "def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "    \"\"\"\n",
    "    Shift input ids one token to the right.\n",
    "    \"\"\"\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "\n",
    "    if pad_token_id is None:\n",
    "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    return shifted_input_ids\n",
    "\n",
    "\n",
    "# define the class\n",
    "class MLT(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_checkpoint):\n",
    "      super(MLT, self).__init__()\n",
    "\n",
    "      self.model = BartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "      self.encoder = self.model.get_encoder()\n",
    "\n",
    "      self.decoder1 = self.model.get_decoder()\n",
    "      self.decoder2 = copy.deepcopy(self.decoder1)\n",
    "\n",
    "      self.lm_head1 = self.model.get_output_embeddings()\n",
    "      self.lm_head2 = copy.deepcopy(self.lm_head1)\n",
    "\n",
    "    def get_config(self):\n",
    "      return self.model.config\n",
    "\n",
    "    def get_decoder(self):\n",
    "      return self.decoder1\n",
    "\n",
    "    def get_lm_head(self):\n",
    "      return self.lm_head1\n",
    "\n",
    "    def get_final_logits_bias(self):\n",
    "      return self.model.final_logits_bias\n",
    "\n",
    "    def get_tokenizer(self):\n",
    "      return self.tokenizer\n",
    "\n",
    "    def forward(self, text, summary1, summary2):\n",
    "      # inputs = self.tokenizer.encode(text, return_tensors=\"pt\")\n",
    "      # target1 = self.tokenizer.encode(summary1, return_tensors=\"pt\")\n",
    "      # target2 = self.tokenizer.encode(summary2, return_tensors=\"pt\")\n",
    "\n",
    "      inputs = text\n",
    "      target1 = summary1\n",
    "      target2 = summary2\n",
    "\n",
    "      encoder_outputs = self.encoder(inputs)\n",
    "\n",
    "      decoder_input_ids1 = shift_tokens_right(\n",
    "                    target1, self.model.config.pad_token_id, self.model.config.decoder_start_token_id\n",
    "                )\n",
    "      \n",
    "      decoder_input_ids2 = shift_tokens_right(\n",
    "                    target2, self.model.config.pad_token_id, self.model.config.decoder_start_token_id\n",
    "                )\n",
    "      \n",
    "      \n",
    "      decoder_outputs1 = self.decoder1(\n",
    "          decoder_input_ids1, \n",
    "          encoder_hidden_states=encoder_outputs[0], \n",
    "          use_cache = False,\n",
    "          output_attentions=self.model.config.output_attentions,\n",
    "          output_hidden_states=self.model.config.output_hidden_states,\n",
    "          return_dict=self.model.config.use_return_dict,\n",
    "          ) \n",
    "\n",
    "      decoder_outputs2 = self.decoder2(\n",
    "          decoder_input_ids2, \n",
    "          encoder_hidden_states=encoder_outputs[0], \n",
    "          use_cache = False,\n",
    "          output_attentions=self.model.config.output_attentions,\n",
    "          output_hidden_states=self.model.config.output_hidden_states,\n",
    "          return_dict=self.model.config.use_return_dict,\n",
    "          )  \n",
    "\n",
    "      lm_logits1 = self.lm_head1(decoder_outputs1[0]) + self.model.final_logits_bias\n",
    "      lm_logits2 = self.lm_head2(decoder_outputs2[0]) + self.model.final_logits_bias   \n",
    "\n",
    "      masked_lm_loss1 = None\n",
    "      masked_lm_loss2 = None\n",
    "      loss_fct = CrossEntropyLoss()\n",
    "      masked_lm_loss1 = loss_fct(lm_logits1.view(-1, self.model.config.vocab_size), target1.view(-1))\n",
    "      masked_lm_loss2 = loss_fct(lm_logits2.view(-1, self.model.config.vocab_size), target2.view(-1))\n",
    "      \n",
    "      # return {\n",
    "      #     'loss1': masked_lm_loss1, \n",
    "      #     'loss2': masked_lm_loss2,\n",
    "      #     'encoder_outputs': encoder_outputs\n",
    "      #     }\n",
    "\n",
    "      return (masked_lm_loss1, masked_lm_loss2, encoder_outputs)\n",
    "\n",
    "\n",
    "# create the object\n",
    "model = MLT(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27590c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLT(\n",
       "  (model): BartForConditionalGeneration(\n",
       "    (model): BartModel(\n",
       "      (shared): Embedding(50265, 768, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  )\n",
       "  (encoder): BartEncoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder1): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder2): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head1): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  (lm_head2): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc85895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "137\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "transcripts_dir = Path(\"./data/ami/transcripts\")\n",
    "abs_summaries_dir = Path(\"./data/ami/summaries/abstractive\")\n",
    "ext_summaries_dir = Path(\"./data/ami/summaries/extractive\")\n",
    "\n",
    "transcripts = []\n",
    "abs_summaries = []\n",
    "ext_summaries = []\n",
    "\n",
    "for file in transcripts_dir.iterdir():\n",
    "  transcripts.append(file.read_text())\n",
    "\n",
    "for file in abs_summaries_dir.iterdir():\n",
    "  abs_summaries.append(file.read_text())\n",
    "\n",
    "for file in ext_summaries_dir.iterdir():\n",
    "  ext_summaries.append(file.read_text())\n",
    "\n",
    "print(len(transcripts))\n",
    "print(len(abs_summaries))\n",
    "print(len(ext_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58b2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_transcripts, val_transcripts, train_abs_summaries, val_abs_summaries = train_test_split(transcripts, abs_summaries, test_size=.2)\n",
    "_, _, train_ext_summaries, val_ext_summaries = train_test_split(transcripts, ext_summaries, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0016b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_transcripts_encodings = tokenizer(train_transcripts, truncation=True, padding=True)\n",
    "val_transcripts_encodings = tokenizer(val_transcripts, truncation=True, padding=True)\n",
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "  train_abs_summaries_encodings = tokenizer(train_abs_summaries, truncation=True, padding=True)\n",
    "  val_abs_summaries_encodings = tokenizer(val_abs_summaries, truncation=True, padding=True)\n",
    "\n",
    "  train_ext_summaries_encodings = tokenizer(train_ext_summaries, truncation=True, padding=True)\n",
    "  val_ext_summaries_encodings = tokenizer(val_ext_summaries, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0e2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transcripts, abs_summaries, ext_summaries):\n",
    "        self.transcripts = transcripts\n",
    "        self.abs_summaries = abs_summaries\n",
    "        self.ext_summaries = ext_summaries\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.transcripts.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.transcripts.items()}\n",
    "        item[\"abs\"] = torch.tensor(self.abs_summaries[\"input_ids\"][idx])\n",
    "        item[\"ext\"] = torch.tensor(self.ext_summaries[\"input_ids\"][idx])\n",
    "        return item\n",
    "\n",
    "    \n",
    "\n",
    "train_dataset = MeetDataset(train_transcripts_encodings, train_abs_summaries_encodings, train_ext_summaries_encodings)\n",
    "val_dataset = MeetDataset(val_transcripts_encodings, val_abs_summaries_encodings, val_ext_summaries_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2175d04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__(), val_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f20ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f49d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartPretrainedModel\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "class DecoderForGeneration(BartPretrainedModel):\n",
    "\n",
    "    def __init__(self, config, decoder, lm_head, final_logits_bias):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.config = config\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "        self.final_logits_bias = final_logits_bias\n",
    "\n",
    "    # def get_encoder(self):\n",
    "    #     return self.get_encoder()\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.model.get_decoder()\n",
    "\n",
    "    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
    "        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n",
    "        self._resize_final_logits_bias(new_num_tokens)\n",
    "        return new_embeddings\n",
    "\n",
    "    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n",
    "        old_num_tokens = self.final_logits_bias.shape[-1]\n",
    "        if new_num_tokens <= old_num_tokens:\n",
    "            new_bias = self.final_logits_bias[:, :new_num_tokens]\n",
    "        else:\n",
    "            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n",
    "            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n",
    "        self.register_buffer(\"final_logits_bias\", new_bias)\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head = new_embeddings\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        decoder_input_ids=None,\n",
    "        decoder_attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        past_key_values=None,\n",
    "        inputs_embeds=None,\n",
    "        decoder_inputs_embeds=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if labels is not None:\n",
    "            # if use_cache:\n",
    "            #     logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n",
    "            use_cache = False\n",
    "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "                decoder_input_ids = shift_tokens_right(\n",
    "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "                )\n",
    "\n",
    "        decoder_outputs = self.decoder(\n",
    "        decoder_input_ids, \n",
    "        encoder_hidden_states=encoder_outputs[0], \n",
    "        use_cache = False,\n",
    "        output_attentions=self.config.output_attentions,\n",
    "        output_hidden_states=self.config.output_hidden_states,\n",
    "        return_dict=self.config.use_return_dict,\n",
    "        )\n",
    "        lm_logits = self.lm_head(decoder_outputs[0]) + self.final_logits_bias\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(lm_logits.view(-1, model.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + decoder_outputs[1:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "        self,\n",
    "        decoder_input_ids,\n",
    "        past=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        decoder_head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        use_cache=None,\n",
    "        encoder_outputs=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # cut decoder_input_ids if past is used\n",
    "        if past is not None:\n",
    "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "            \"past_key_values\": past,\n",
    "            \"decoder_input_ids\": decoder_input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"head_mask\": head_mask,\n",
    "            \"decoder_head_mask\": decoder_head_mask,\n",
    "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
    "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
    "        }\n",
    "\n",
    "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
    "        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def _reorder_cache(past, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past:\n",
    "            # cached cross_attention states don't have to be reordered -> they are always the same\n",
    "            reordered_past += (\n",
    "                tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
    "            )\n",
    "        return reordered_past\n",
    "\n",
    "\n",
    "myDecoderModel = DecoderForGeneration(model.get_config(), model.get_decoder(), model.get_lm_head(), model.get_final_logits_bias())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec54ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderForGeneration(\n",
       "  (decoder): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDecoderModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e5dd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4284777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2959250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tanik_1821cs08/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "22.1462345123291\n",
      "27.07195281982422\n",
      "35.37154006958008\n",
      "16.892127990722656\n",
      "11.50663948059082\n",
      "12.230772018432617\n",
      "12.456787109375\n",
      "10.93858528137207\n",
      "10.19719123840332\n",
      "15.716581344604492\n",
      "14.266718864440918\n",
      "10.413127899169922\n",
      "11.35013198852539\n",
      "10.303816795349121\n",
      "10.763803482055664\n",
      "10.052706718444824\n",
      "9.937082290649414\n",
      "9.871136665344238\n",
      "10.39605712890625\n",
      "8.885883331298828\n",
      "11.825105667114258\n",
      "10.334107398986816\n",
      "10.85279369354248\n",
      "9.064637184143066\n",
      "10.182108879089355\n",
      "9.992914199829102\n",
      "10.915255546569824\n",
      "9.562410354614258\n",
      "9.258066177368164\n",
      "11.534631729125977\n",
      "9.960484504699707\n",
      "9.46107006072998\n",
      "9.662081718444824\n",
      "9.197023391723633\n",
      "8.208890914916992\n",
      "9.274457931518555\n",
      "9.273035049438477\n",
      "9.481298446655273\n",
      "9.641237258911133\n",
      "9.544295310974121\n",
      "8.884872436523438\n",
      "9.377571105957031\n",
      "9.1554594039917\n",
      "10.0084810256958\n",
      "9.463756561279297\n",
      "8.532269477844238\n",
      "9.268834114074707\n",
      "9.227331161499023\n",
      "9.234543800354004\n",
      "8.63695240020752\n",
      "8.017560958862305\n",
      "9.537971496582031\n",
      "9.401809692382812\n",
      "10.064441680908203\n",
      "8.066149711608887\n",
      "Validation\n",
      "17.15017318725586\n",
      "12.102758407592773\n",
      "11.182292938232422\n",
      "14.251142501831055\n",
      "14.240070343017578\n",
      "15.5402250289917\n",
      "11.912895202636719\n",
      "15.878951072692871\n",
      "14.292688369750977\n",
      "14.252607345581055\n",
      "14.180601119995117\n",
      "13.320838928222656\n",
      "15.0430269241333\n",
      "13.516977310180664\n",
      "1\n",
      "10.418695449829102\n",
      "8.8264741897583\n",
      "9.95524787902832\n",
      "8.701519012451172\n",
      "10.165536880493164\n",
      "8.836002349853516\n",
      "8.599864959716797\n",
      "8.493459701538086\n",
      "8.71328353881836\n",
      "7.912876129150391\n",
      "8.917078018188477\n",
      "8.942806243896484\n",
      "8.890825271606445\n",
      "9.379801750183105\n",
      "8.82522964477539\n",
      "9.461997032165527\n",
      "9.192558288574219\n",
      "8.08121395111084\n",
      "10.386093139648438\n",
      "9.72278118133545\n",
      "9.309350967407227\n",
      "8.742700576782227\n",
      "8.488775253295898\n",
      "7.782260417938232\n",
      "8.982489585876465\n",
      "8.941427230834961\n",
      "8.348237991333008\n",
      "9.30837631225586\n",
      "8.735413551330566\n",
      "8.791879653930664\n",
      "8.27717399597168\n",
      "9.341490745544434\n",
      "9.105413436889648\n",
      "8.585002899169922\n",
      "8.962278366088867\n",
      "9.151272773742676\n",
      "7.991846084594727\n",
      "9.506848335266113\n",
      "9.314397811889648\n",
      "8.278648376464844\n",
      "9.34217643737793\n",
      "8.568098068237305\n",
      "8.800151824951172\n",
      "9.583929061889648\n",
      "9.472830772399902\n",
      "9.367945671081543\n",
      "8.472208023071289\n",
      "11.565128326416016\n",
      "10.35720157623291\n",
      "8.806879043579102\n",
      "8.570588111877441\n",
      "9.366687774658203\n",
      "8.68154525756836\n",
      "9.507649421691895\n",
      "9.672821998596191\n",
      "Validation\n",
      "14.286809921264648\n",
      "10.450613975524902\n",
      "9.913664817810059\n",
      "12.053548812866211\n",
      "12.001672744750977\n",
      "13.014863967895508\n",
      "10.315025329589844\n",
      "12.524581909179688\n",
      "12.09890079498291\n",
      "12.12696647644043\n",
      "11.992379188537598\n",
      "11.385985374450684\n",
      "12.56993293762207\n",
      "11.497267723083496\n",
      "2\n",
      "7.772993564605713\n",
      "9.316967010498047\n",
      "9.201460838317871\n",
      "8.579323768615723\n",
      "8.759220123291016\n",
      "8.198787689208984\n",
      "8.895423889160156\n",
      "8.6638765335083\n",
      "8.463871002197266\n",
      "8.933349609375\n",
      "9.378803253173828\n",
      "8.802144050598145\n",
      "8.733047485351562\n",
      "9.029644012451172\n",
      "8.989702224731445\n",
      "8.896170616149902\n",
      "9.24632740020752\n",
      "9.316427230834961\n",
      "8.703734397888184\n",
      "8.49317741394043\n",
      "8.83782958984375\n",
      "8.69282341003418\n",
      "8.324869155883789\n",
      "8.156659126281738\n",
      "7.874537467956543\n",
      "8.552735328674316\n",
      "8.497764587402344\n",
      "9.333038330078125\n",
      "8.845657348632812\n",
      "10.980352401733398\n",
      "9.811620712280273\n",
      "9.237911224365234\n",
      "9.131241798400879\n",
      "8.334036827087402\n",
      "9.031087875366211\n",
      "9.533075332641602\n",
      "9.235199928283691\n",
      "7.9635090827941895\n",
      "9.058008193969727\n",
      "8.21047592163086\n",
      "7.2340497970581055\n",
      "8.013201713562012\n",
      "8.107674598693848\n",
      "8.636011123657227\n",
      "8.966790199279785\n",
      "9.339573860168457\n",
      "8.657828330993652\n",
      "8.78604507446289\n",
      "9.275703430175781\n",
      "9.013832092285156\n",
      "8.910318374633789\n",
      "8.19184684753418\n",
      "9.082919120788574\n",
      "8.84509563446045\n",
      "9.021829605102539\n",
      "Validation\n",
      "13.257997512817383\n",
      "10.098169326782227\n",
      "9.679150581359863\n",
      "11.334396362304688\n",
      "11.27481746673584\n",
      "12.1981782913208\n",
      "9.937699317932129\n",
      "11.641813278198242\n",
      "11.440406799316406\n",
      "11.504426956176758\n",
      "11.295026779174805\n",
      "10.849048614501953\n",
      "11.765296936035156\n",
      "10.954511642456055\n",
      "3\n",
      "8.872722625732422\n",
      "9.602096557617188\n",
      "8.287114143371582\n",
      "9.4213228225708\n",
      "8.584770202636719\n",
      "8.273439407348633\n",
      "8.81588077545166\n",
      "9.239690780639648\n",
      "8.743185043334961\n",
      "8.259407043457031\n",
      "8.48946762084961\n",
      "8.350849151611328\n",
      "8.733983993530273\n",
      "8.959990501403809\n",
      "8.80473518371582\n",
      "8.693775177001953\n",
      "9.014616966247559\n",
      "7.6616106033325195\n",
      "9.73798656463623\n",
      "8.849678993225098\n",
      "9.023994445800781\n",
      "8.554557800292969\n",
      "8.604726791381836\n",
      "9.606522560119629\n",
      "8.019120216369629\n",
      "8.724340438842773\n",
      "8.759350776672363\n",
      "11.687494277954102\n",
      "9.965812683105469\n",
      "9.552298545837402\n",
      "8.080438613891602\n",
      "8.908941268920898\n",
      "8.697770118713379\n",
      "8.045936584472656\n",
      "9.21100902557373\n",
      "9.061714172363281\n",
      "8.422019958496094\n",
      "8.817130088806152\n",
      "8.181388854980469\n",
      "7.425342559814453\n",
      "8.984851837158203\n",
      "7.81106424331665\n",
      "8.803227424621582\n",
      "8.486109733581543\n",
      "8.607961654663086\n",
      "9.144842147827148\n",
      "8.545705795288086\n",
      "8.584928512573242\n",
      "9.150724411010742\n",
      "8.991338729858398\n",
      "8.396846771240234\n",
      "8.51246166229248\n",
      "7.756058692932129\n",
      "7.760098457336426\n",
      "8.871334075927734\n",
      "Validation\n",
      "13.245292663574219\n",
      "10.032045364379883\n",
      "9.610466003417969\n",
      "11.274482727050781\n",
      "11.21934700012207\n",
      "12.160337448120117\n",
      "9.853471755981445\n",
      "11.714465141296387\n",
      "11.371562004089355\n",
      "11.438800811767578\n",
      "11.240111351013184\n",
      "10.776156425476074\n",
      "11.719328880310059\n",
      "10.870572090148926\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "def train(model, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss': [], 'validation_loss': []}  \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        # model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data['input_ids'], data['abs'], data['ext'] = data['input_ids'].to(device), data['abs'].to(device), data['ext'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data['input_ids'], data['abs'], data['ext'])\n",
    "            loss = output[0] + output[1]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.item())\n",
    "            print(loss.item())\n",
    "\n",
    "        print(\"Validation\")\n",
    "        model.eval()\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            with torch.no_grad():\n",
    "              data['input_ids'], data['abs'], data['ext'] = data['input_ids'].to(device), data['abs'].to(device), data['ext'].to(device)\n",
    "              output = model(data['input_ids'], data['abs'], data['ext'])\n",
    "              loss = output[0] + output[1]\n",
    "              useful_stuff['validation_loss'].append(loss.item())\n",
    "              print(loss.item())\n",
    "\n",
    "              predictions = myDecoderModel.generate(data['input_ids'], encoder_outputs=output[2])\n",
    "              labels = data['abs'].cpu()\n",
    "\n",
    "              decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "              # Replace -100 in the labels as we can't decode them.\n",
    "              labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "              decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "              \n",
    "              # Rouge expects a newline after each sentence\n",
    "              decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "              decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "              metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "              \n",
    "        result = metric.compute(use_stemmer=True)\n",
    "        # Extract a few results from ROUGE\n",
    "        result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "    \n",
    "    return (useful_stuff, result)\n",
    "\n",
    "training_results = train(model, train_loader, validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2a1e396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f39bc45ca30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABD2UlEQVR4nO3deXxU1d348c+ZySSTfYcEkkDYN2UREESRuuK+VK3VqrW22Gr7VFvb2u1XfZ4+z2Nrba1t1ccFta0bFfcqriAKsgRk3yGQhOwhezLJZOb8/jh3JhOSQJBMArnf9+vFayY3M/eeuRm+93u/59xzldYaIYQQ9uHo7wYIIYToWxL4hRDCZiTwCyGEzUjgF0IIm5HAL4QQNhPR3w3oibS0ND18+PD+boYQQpxU1q1bV6m1Tj98+UkR+IcPH05eXl5/N0MIIU4qSqkDXS2XUo8QQtiMBH4hhLAZCfxCCGEzJ0WNXwghjpXX66WoqAiPx9PfTQk7t9tNVlYWLperR6+XwC+EGJCKioqIj49n+PDhKKX6uzlho7WmqqqKoqIicnNze/QeKfUIIQYkj8dDamrqgA76AEopUlNTj+nMRgK/EGLAGuhBP+BYP6dtAv+6A4fYVlzX380QQoh+F7bAr5RyK6XWKKU2KqW2KqXut5bfp5Q6qJTaYP27OFxtCHXfm9v404e7+mJTQggBQE1NDY8++ugxv+/iiy+mpqam9xtkCWfG3wKco7WeDEwB5iulZlm/+5PWeor1750wtiHI4/Xh9fn7YlNCCAF0H/h9Pt8R3/fOO++QlJQUplaFcVSPNrf2arB+dFn/+u12X16fH59f7jYmhOg79957L3v37mXKlCm4XC7i4uLIzMxkw4YNbNu2jSuvvJLCwkI8Hg8//OEPWbBgAdA+TU1DQwMXXXQRZ555JitXrmTo0KG88cYbREdHH1e7wjqcUynlBNYBo4C/aa1XK6UuAr6vlLoZyAN+rLWu7uK9C4AFADk5OcfdltY2P365zaQQtnT/W1t7vY9vwpAEfnPZxCO+5oEHHmDLli1s2LCBZcuWcckll7Bly5bgsMuFCxeSkpJCc3MzM2bM4Ktf/Sqpqakd1rF7925efPFFnnzySa677joWL17MN77xjeNqe1g7d7XWPq31FCALmKmUmgQ8BozElH9KgIe6ee8TWuvpWuvp6emdJpc7Zq0+LRm/EKJfzZw5s8NY+0ceeYTJkycza9YsCgsL2b17d6f35ObmMmXKFABOO+009u/ff9zt6JMLuLTWNUqpZcB8rfUfAsuVUk8Cb/dFG7w+PxL3hbCno2XmfSU2Njb4fNmyZXz44Yd8/vnnxMTEMG/evC7H4kdFRQWfO51Ompubj7sd4RzVk66USrKeRwPnATuUUpkhL7sK2BKuNoTy+vz4JfILIfpQfHw89fX1Xf6utraW5ORkYmJi2LFjB6tWreqzdoUz488EnrPq/A5gkdb6baXUP5RSUzAdvfuB28PYhiCvz49PavxCiD6UmprKnDlzmDRpEtHR0QwePDj4u/nz5/P4449z6qmnMnbsWGbNmnWENfWucI7q2QRM7WL5TeHa5hHagtenpdQjhOhzL7zwQpfLo6KiePfdd7v8XaCOn5aWxpYt7UWRe+65p1faZIsrd70+E/Gl1COEELYJ/ObCLRnVI4QQNgv8Mo5fCCFsEvhbJfALIUSQPQJ/m5R6hBAiwBaBP9i5K3FfCCHsEvgl4xdCnPji4uL6ZDu2CPyBUo/U+IUQwiY3Ww+O6pGMXwjRh372s58xbNgw7rjjDgDuu+8+lFIsX76c6upqvF4vv/3tb7niiiv6tF02Cfwm4MuUDULY1Lv3Qunm3l1nxilw0QNHfMn111/PXXfdFQz8ixYtYsmSJdx9990kJCRQWVnJrFmzuPzyy/v0/sA2CfyBGn8/N0QIYStTp06lvLyc4uJiKioqSE5OJjMzk7vvvpvly5fjcDg4ePAgZWVlZGRk9Fm7bBH4A+P4tWT8QtjTUTLzcLrmmmt45ZVXKC0t5frrr+f555+noqKCdevW4XK5GD58eJfTMYeTLQK/NzCOXwK/EKKPXX/99XznO9+hsrKSTz75hEWLFjFo0CBcLhdLly7lwIEDfd4mWwT+VhnOKYToJxMnTqS+vp6hQ4eSmZnJjTfeyGWXXcb06dOZMmUK48aN6/M22SLwe4Olnn5uiBDCljZvbu9YTktL4/PPP+/ydQ0NDX3SHluM4/e2WaN6JOMXQgh7BP5gqUdSfiGEsEfglwu4hLAnu4zkO9bPaa/Ab5MvgRAC3G43VVVVAz74a62pqqrC7Xb3+D026dxtn51Ta92nV8gJIfpHVlYWRUVFVFRU9HdTws7tdpOVldXj19si8AcmaQMT/J0S94UY8FwuF7m5uf3djBOSrUo9ICN7hBDCFoG/Y8YvgV8IYW+2CPyhGb8EfiGE3dki8Lf62oO9lHqEEHZni8DfIeOXqZmFEDYXtsCvlHIrpdYopTYqpbYqpe63lqcopT5QSu22HpPD1YYAKfUIIUS7cGb8LcA5WuvJwBRgvlJqFnAv8JHWejTwkfVzWHUY1SOBXwhhc2EL/NoITDXnsv5p4ArgOWv5c8CV4WpDQGtbe7CXaRuEEHYX1hq/UsqplNoAlAMfaK1XA4O11iUA1uOgbt67QCmVp5TKO94r7yTjF0KIdmEN/Fprn9Z6CpAFzFRKTTqG9z6htZ6utZ6enp5+XO3oWOM/rlUJIcRJr09G9Wita4BlwHygTCmVCWA9lod7+x1H9UjkF0LYWzhH9aQrpZKs59HAecAO4E3gFutltwBvhKsNAaFX7so4fiGE3YVzkrZM4DmllBNzgFmktX5bKfU5sEgpdRtQAFwbxjYAHS/gkuGcQgi7C1vg11pvAqZ2sbwKODdc2+2KjOMXQoh2trlyN9JpPqpPrtwVQticPQJ/m58oVyDwS8YvhLA3WwT+Vp/G7XICUuoRQghbBH6vz4/byvgl8Ash7M42gT8qwmT8UuoRQtidbQK/ZPxCCGEM+MDv92u8Po07IlDj7+cGCSFEPxvwgd9r3Xkl0LkrpR4hhN0N/MBvXbUbFWGVeiTwCyFsbuAHfmueHneklfFLjV8IYXMDP/Bbl+pKjV8IIYwBH/hbrcAfuHJXSj1CCLsb8IE/UON3yzh+IYQAbBH4A6N6ZBy/EEKADQJ/4CYsMlePEEIYAz7wN3t9AMQERvXItMxCCJsb+IG/1QT+uChzzxkZzimEsLuBH/itjD/ObQK/lsAvhLC5AR/4PVbgjw1k/DKqRwhhcwM+8DdZpZ7YSAn8QggBNgj8h9f4ZVSPEMLuBn7g9x4e+PuzNUII0f8GfuBv9eFQ7RdwSalHCGF3Az/we31Eu5w4HAqQUo8QQtgj8EdG4FQm8EvGL4SwuwEf+D2tPqIjHSEZfz83SAgh+lnYAr9SKlsptVQptV0ptVUp9UNr+X1KqYNKqQ3Wv4vD1QYwwzmjXU6suC/TMgshbC8ijOtuA36stV6vlIoH1imlPrB+9yet9R/CuO2gQI3faUV+mbJBCGF3YQv8WusSoMR6Xq+U2g4MDdf2umNq/E4cSjp3hRAC+qjGr5QaDkwFVluLvq+U2qSUWqiUSu7mPQuUUnlKqbyKioovvW3PYRm/lHqEEHYX9sCvlIoDFgN3aa3rgMeAkcAUzBnBQ129T2v9hNZ6utZ6enp6+pfeflNrx4xfpmUWQthdWAO/UsqFCfrPa61fBdBal2mtfVprP/AkMDOcbWhu9RHtigh27kqNXwhhd+Ec1aOAp4HtWus/hizPDHnZVcCWcLUBrFJPpAOlFA4l0zILIUQ4R/XMAW4CNiulNljLfgF8XSk1BdDAfuD2MLYhOKoHwOlQcgGXEML2wjmq5zNAdfGrd8K1zS7a0CHwK6Wk1COEsL0BfeVuS5sfrSHamovfqZSM6hFC2N6ADvyBufijrZk5nQ4lUzYIIWxvQAf+Jmsu/ujIQKlHJmkTQogBHfiDGX+g1ONQcuWuEML2BnTgD9xoPTiqR8moHiGEGNCBv/mwwO+QGr8QQgzswN/U2rHG71AyV48QQgzowN8+qiek1CM1fiGEzQ3owO85bFSPwyHj+IUQYkAH/sNr/DKqRwghBnjg71zjV/gk7gshbG5AB/7Dh3NK564QQgzwwN/c6sPpULicZq44KfUIIcQAD/xNrT5iXE6Udfcth1zAJYQQPQv8SqkfKqUSlPG0Umq9UuqCcDfueEW5HGQkuoM/O5Rk/EII0dOM/1vW/XIvANKBW4EHwtaqXvKz+eP44EdnB3+WG7EIIUTPA3/ghioXA89orTfS9U1WTmgyZYMQQvQ88K9TSr2PCfzvKaXiAX/4mhUeDoWUeoQQttfTWy/eBkwB9mmtm5RSKZhyz0lFZucUQoieZ/yzgZ1a6xql1DeAXwG14WtWeDikxi+EED0O/I8BTUqpycBPgQPA38PWqjBxKoVUeoQQdtfTwN+mtdbAFcCftdZ/BuLD16zwcDiQ2TmFELbX0xp/vVLq58BNwFlKKSfgCl+zwkMu4BJCiJ5n/F8DWjDj+UuBocCDYWtVmMiUDUII0cPAbwX754FEpdSlgEdrfVLW+CXwCyHsrqdTNlwHrAGuBa4DViulrglnw8JBKYXvpLv6QAgheldPa/y/BGZorcsBlFLpwIfAK929QSmVjRn5k4G52OsJrfWfrWsAXgaGA/uB67TW1V/2AxwLp0OmZRZCiJ7W+B2BoG+p6sF724Afa63HA7OAO5VSE4B7gY+01qOBj6yf+4TU+IUQoucZ/xKl1HvAi9bPXwPeOdIbtNYlQIn1vF4ptR3TKXwFMM962XPAMuBnx9TqL0nJzdaFEKJngV9r/ROl1FeBOZjJ2Z7QWr/W040opYYDU4HVwGDroIDWukQpNaib9ywAFgDk5OT0dFNH5FRys3UhhOhpxo/WejGw+Fg3oJSKs953l9a6LnBTlB5s7wngCYDp06f3SrR2OiTjF0KIIwZ+pVQ90FWkVIDWWicc5f0uTNB/Xmv9qrW4TCmVaWX7mUB592voXQ6l8MuoHiGEzR2xg1ZrHa+1TujiX3wPgr4Cnga2a63/GPKrN4FbrOe3AG8czwc4FjItsxBCHEOp50uYg5niYbNSaoO17BeYO3ctUkrdBhRgrg3oE3IHLiGECGPg11p/Rvd36To3XNs9EocM5xRCiB6P4x8QzJQN/d0KIYToX7YK/A6FlHqEELZnr8DvkHH8Qghhq8DvlCt3hRDCZoFfOneFEMJegV/JBVxCCGGvwO+Ue+4KIYTNAr/cgUsIIewV+JVSaA1agr8QwsZsFfidDnMhsYzlF0LYmT0Dv2T8Qggbs1Xgd1j3ApC4L4SwM5sFfvMopR4hhJ0N7MC/6z347OHgj1LqEUKIgR7493wIKx4O/hgo9ch8PUIIOxvYgd8VDd7m4I+BjF/ivhDCzgZ44I+BNg+BeRoinCbwe30yb4MQwr4GeOCPNo9tJuuPdjkB8Hh9/dUiIYTodwM88MeYR6vc47YCf7MEfiGEjQ3wwG9l/N4mANwu83E9Xin1CCHsyyaB/7CMv1UyfiGEfQ3wwB8o9QQyfqvG3yaBXwhhXwM88HfM+IOdu4dn/Lveg+INfdgwIYToPwM88Pcw43/nJ/DJ7wD4dHcFjS1tfdZEIYToawM88B9e4w/p3G1rgZZ68/uWeqgpoKaplZsXruHFNQX90VohhOgTAzzwdxzOGR3aufv+r+C5y83vWxugpoCGlja0hn2Vjf3RWiGE6BNhC/xKqYVKqXKl1JaQZfcppQ4qpTZY/y4O1/aBLoZzhpR6ivKg5gC0tYKvFVrqaG2oBqCgqimszRJCiP4Uzoz/WWB+F8v/pLWeYv17J4zb75TxR0VYpZ6WNqjaY0o8rQ3Bl/urDwBQcEgCvxBi4Apb4NdaLwcOhWv9PXJY565SCrfLgbO5ElrqTKbfFNLEGlPbP1jT3D6fz6rHYP9nfdlqIYQIq/6o8X9fKbXJKgUld/cipdQCpVSeUiqvoqLiy23J6QLl7DBDp9vlJK5xf/tr6ouDTx21hYC5UUtxTbO5VdeH98Pap77c9oUQ4gTU14H/MWAkMAUoAR7q7oVa6ye01tO11tPT09O/3NaUMll/a3vpJtrlJKFhf/tr6kqCTyPqCoPPD1Q1mbOBtmawSkBCCDEQ9Gng11qXaa19Wms/8CQwM+wbdUUHSz1gMv4UT0ggD8n4IxuKgs8PHGqCOuvnGgn8QoiBo08Dv1IqM+THq4At3b221xx2Mxa3y0maJ2ScfiDjT8jC3dge+AuqGqHW+rmpClraO4GFEOJkFs7hnC8CnwNjlVJFSqnbgN8rpTYrpTYBXwHuDtf2g1wxHTL+TEcNGd4CSMoxC+qtwD94AjGNRUxU+0lyO02pp/Zg+3pqDsD+FeD1hL3JQggRThHhWrHW+utdLH46XNvrVmjGv+VVFlbdap4PvdqM4qkvNT8PP5PI3e/z76hfUOlI49nSmyAjZGqHne/Ax7+Fq5+EU6/r288ghBC9aGBfuQtWxm8F/up8AP4vZgGc9WOzLJDxz1zAP2a+wd2t36MlIoFvNz1lSj3uJPP79X83j01Vfdd2IYQIAxsE/pDO3eYavMrFvyIuhZQRZll9iRnyGeGmzJnJG/os1gy+liTqYf+nkHEKRMYFx/gH5/cRQoiTlE0Cv5Xxe2ppdsabuXpc0Sbg+9sgKg6UwuP14XY5qUieYl7fWAGJWZA0rH19EviFECc5GwT+kM5dTw0eZzwtbT4zxj8q3iyPjDO/bjOBvzVxJNXaLCNhKCSHBP5WGd0jhDi52SDwd8z4WyLi22+9GJVgHgOB3+vHHeEg1h3JOv9o87vELEjONc/diTKsUwhx0rNB4A/p3G2uweuKx9NmzcMTyPijAoHfZPyxURGs8481v0vMglnfhWuegcSc3sv4fV4ZGiqE6Bc2CPxW567W4KnF60rE59dmErbDSz1eP1EuJ3FRESzxz6A5fTIMmWrG/E+62hwgeqvG/+5P4flremddNQXwv9lQtrV31ieEGNDsEfi1z2TYnhp8kaa80+z1hWT85tHj9RHtchAbFUG+zmTbpa9DbFr7uiK7Cfxaw7Y3zdz+PVW6Gar2fskPdZiKnWa20YodvbM+IcSAZoPAH5iauRE8tfiiEgET5Nsz/tjgMrfLSVyUuWFLQ8th9+aNiuu61FO0FhbdBLve7Xm7ag+Cp/aYPkq3Gq3ZS3trfUKIAc0Ggd+6C1dDBWg/2m0F/tYuSj1t7TV+oPNN16Piu+7cLf7CPDb2cPpoXxs0lJqDkc97TB+nSxL4hRDHwAaB38r4rSt0g4G/zddF564ft8tBbKQJ/A2HB/7I+K4z/pKN5rGp+sht8XpMHb6+BLTVweypO7bP05Vg4O+FdQkhBjwbBH4r4w9MzWBNwdDc6qMlwgR8b0RIqSfCSbzbCvyewzN+q9Tj93dcHgj8zYdg3zJ4+NT2OYBCrX0K/m+uqe8HeGq+5AcL0VhprUsyfiHE0dkg8HfM+J0xSYAp47yyuQaAfCteerx+3JFHKPVYJaEOWb/XA+XbzfOmQ3BwnZnJc/XjndtSstFcKbz7vfZlvRGspdQjhDgGNgj8VsZvzbvviDF3e/zdezvZWGE6b8tbXQC0WBm/y+kgMsJBQ2sXGT90DPzlW82oITAZfyD7Xvu0OSA0hNT9K6wDxK6jBP4ti2HDCz3/jA3l3a/L74Otr3c+SxFC2NbAD/yRVsZv3VQlwsr4NxbWkJ05GIDSZpPhN3t9uF1ml8RFRXTRuWtd6Rvo4F3+IHz0X+Z5ygiT8TeUm7OMljp4dBY8PAk+f9QE4Mrd5rX17bd77DJYL3sAVv6l558xcLBp6aLGv/Md+NctUPB5z9cnhBjQwjYf/wkjZSSgoGAlAK64FMDMtDkmewhUwsFmJ20+P21+jdtlhnLGRjlpPHw4Z7DUU29G5nz834A28/lkToaSTejIGFTGKTDjO+bCsZ3vwHs/N69r85i2oM26Whs6B35PLVTugtge3mdY6yOXeoryzGNDF30OQghbGvgZvzsB0sdBczWgiIxNCv5q9NSzWBdzJiuacoLTOAQy/tjIiM6jegKlnpYGa15+DefdD99bCTGpNNRUUFZcaIL2qdfCabfA1/4J0Snw2Z/Me3PPMo+DxpvHw4P1wfXmsanKnCUcyfI/mKmj/d6u1wWmzwHMWUFrY3t/xOGaa+TKX2FbPr+mzWefcujAD/wAWaeZR3cC0ZGmnp+Z6CY3O5u3xv2erTUuc0EXEG1l/F2WegIZf0s9NJSZ5ykjIDoJolOI8dcT01rZMVt3umDcxe1Z+aSvmse0saAcXQR+K0PXflM6evtuWPdc589UVwIf/xd8eL/5OW5w53X5fVC8wTxvrIA1T8BjZ0BpF7c6/uT38OS5He5PbFeVDS3UNvfC9RXipPGjRRv44Usb+rsZfcYegX/odPPoTgwG9rmj01FKkZ0SQ2Orj5IaM2FaVLDU01XGb437b21o71CNG2Qeo5NxoEnQ9ejDyzQTrjSPCVmQM9s8T8zCF5nAS59upvBQ+z2BKVrX/rzuIOQ9A2/9B7y6AJ6+APZ9Yn4XOEAEHlNGmtJS6AVhlbtNWQpM4D+Ubw4oS+6FgtUdDwCFq6Gtuf1iNBtb8Pc8fvV6FwdHMWDtLmtg80H7jIqzR+DPCgT+JKIjnfxs/ji+M9fcgSsnxXT+7iozATJQ449zm8D/8Ie7WLrDCvKBwN9SD40dA7+OTg5ursGV0nH7uWdDVKIp76SOhtnfh4lX4XHGE+VrYMvBWlOCWfILE4ATrRvBl24CNMQOgs2vmLl9Xvw6FK5tr90HpI40j4GLuGoPQr51kHDFmlJPfYk5y9j/KSy8AJ46F/YuNXMMBa4tkE5gims85m8ibKO22UtprQe/X/d3U/rEwO/cBUgfb0baWFftfm/eyOCvslPMcM/d5WakjjvCGtUTGUFlfQuPfLSbeWMH8ZVxgzqO4w8M6Yw1gd/jSsIaOEq5P4H40O1HRML1/4SYNHA44ML/BqDZGUcCTeyrboaD/4BVfzOvn3IDfP7X9uz7qsch+3RTo194Abz+PXPAiU62+i6A1FHm0VMDLjf8dbo5A4iMhyFTTMbf2gijzoOsGWa66c//Bi9eD1c+Br4W8/6CVcezpweE2mYv5fWe4NxNYuCra/bS6vNT2djCoHh3fzcn7OyR8TsjYOo3YOQ5nX6VnWwy/t2HZfyxURHUedrwa9hWbGXRrmiTMbc0mPH5rthgh2+9IyG4zoPeuM5tyJ0Lgyd0WNSoYklQjRRWN0FtoekvWLAM5txlXhAI/Ek5Zjvxg+GcX0PVbjiwwvQXBG4GH7iHcEsd1BSaoD/qfLjgv0z9v7EC6opNwD/7p+bgcuO/TD/Auz8z7x15jjnjsPGY/9Y2P81eH34N+ZWN/d2c46a17lyyFB20+fzUW/soUPId6OwR+AEufhDO+lGnxbFREaTGRrLz8FJPVHumV1rnoaqhxdyuMTK+vXM3UN8HamkP9vnNcRRVNwU7jAN2l9XzwLs70NqcTtYRQwJNFFU3m8CfPNzM/x+TCo6I9hp8wtD2lUy4ov3n7NNh2Blm1FBMqlnmqTXrAph7D0y/1UwtXVdiLjCLH9K+roQhMPFKU7aKSYNTrjXvt/H0zvWe9j6SwFngyWzJllJm/veHHGo8hinDbaYuZGqW4hp7DG6wT+A/golDE03wpX1UT2DahoBNRbU89P5OfK5Yq3O3zGTSlhrdHvg/L3dw7kOf8NzK/R3W8cKaAh7/ZG9wWzX+GBJUE0XVTeYCs8Rs80KHw4wM8ntNQA9chAZmlNDp3zVnHtkz4bz7TKnGKmN1CPyB9cWmmY5bgITMjh9+5u3mceg0yJllnheu7sFeG5hCR/PsKeulm+70o11lDTS1+theIhP4dSf0b15cKxm/bZw5KjX4PDiO3wr8Z44yN2L5w/s7+cvHe6j2RVmduxUQ1z56p8oXjU8rPLhYsruRljY/+yo6lgo2FNYAsL+qMfieBBqpqK4160vKbn9x4AYwodl+wOzvwx2rzBlC+lgYO/+wwF9kzhjiM6x1hYwyij8s8GdNh9O/B9O/Ze4tfOcamHbL0XbZgBWa/e2pOPkz/soG03ezs/TkP4iFS2jgL5GM3z7mjGq/y5Y7ZBw/wNlj0hmaFM1Wq85f5Y3skPFrrdFaU+tpo5ZY6p0pmKtzoaSuPXtobfMH17Hfqh1XeN3EqhbSvNYUDomhgT+987IAh8ME/FBuq4/BY9X4E4aAw9lxXdD5QKIUXPQAjL0IlKLcPQytVLf7aqALBIHU2Eh2l538gb+i3gT+3eUS+LtT09ReBiuulcB/XJRSC5VS5UqpLSHLUpRSHyildluPyUdaR18Zn5FAamwkAFFWxp8eHwXAtGHJjM80QTUnJYb9LfH4y7ab0TRxg/nb0j1c+pfPqG32Uq3jaXWbs4dIp4PSkC/R9pI6Wq2rg/dVNqK1pqzVbGO8MlNIdAz8Vv9BYlbPPkRkPKDaM/6uDiLQudQToqzOwxn/+zEfbS/v2Ta/hHqPl3P+sIzV+6rCto3jUWcF/mnDksmvbDT3Zj6JVVgZ/64BcBALl8DBPiPBTbF07h63Z4H5hy27F/hIaz0a+Mj6ud85HIozrKw/kPHPHpHK63fO4bRhyZwxMpX0+Cj+56pT+LfvdBwNJkP3xaTx7MoDbC2uo7jGwxd6DBHDz+D03BQumzyEkhoPbT4//1x1gKU7TTBNi4tkf2UjTa0+qtrMANDxjgOmIV2Venoa+B0Ok/UHavyJXazLFds+0VwXCg810ebX7CjtWA8urfWwvuAoN5npoQNVTeyrbORf64p6ZX29rc7q3J2SnUSbX5/0nX2BjH9XaX1wUIHoKHCwH58Zf9L/vXsqbIFfa70cOHTY4iuAwPwDzwFXhmv7x+qGmTlcNCmDOOvuWw6HYkp2EgC3zhnOynvPYfbIVNZEzcajTMDeUusO1lC3FtfyP5E/YPC1D/Hy7bMZPTiO+pY23tlSyq9e38LDH+4mPT6K03NTya9spKqhlTpMp+0UtRc/jo7198CIocQuavzdaItMwFMXMmwzIJDxJ2Sa0s5h/vLRblburaTKGvkR6HwOePjDXdyycE2vBI7A/lq6o/yEvFgmkP1NGGIOkIWHTu5AUNnQQkykk/qWNkrr7JHNHqvA33xcZgIVDS3BM/OBrK9r/IO11iUA1uOg7l6olFqglMpTSuVVVPTwXrbHYfbIVB77xmk4HJ0Do1IKl9OB06G4ZtYY3vTOBOCpLxoJvHxrcR2J0a7gezITzUUgy6yrfqNdTmaNSCU3LZbC6mZKaptZ5x+DzxnNbOc26lxpZsROwJFq/N3Y3JhI664Pzf0BQs8eIuMgwt25YxeTzT/0wS5eWVdEVYMJ/AdrmtlQWMP8h5dT5/Gyr7KRek9bMHs8HoFtVDW2sqGo5rjX19vqmtuIdDoYPciM0iqsbjrKO05cjS1tNLX6OD3XXEku5Z6u1TR5iXY5yU2NRQ+Q6zeO5oTt3NVaP6G1nq61np6e3sMpivvAPReOZdTlP2Nj1DQ+PpTC12aYANvU6iOhQ+A3ZwWf7KpgaFI0n/x0Hr+9chLD02Lx+TUbCmuoIZ7q8TcAsM+b0nHc/+gL4IwfQOaUHrWrvN7D483nkeC3yjShGb9SZsRO2uhO7/vYOjBV1LdwqNEE9qLqZpbuKGdHaT1bDtZSUGWC375e+A9RZW1DKfg4jH0JX1Zts5eE6AgyEtxEOJQZanuSChyoA4MX7DKk0+/XvL+1tMdnlLXNXhKjXcwbm05khINnV+aHuYX9r68Df5lSKhPAejzx/uf3wLSZc5j886Ws+s3l/PbKU4IjgLrK+KsaWxmXEc+geDeJ0S5y08z9ffMOmJq5b9ad+B0uDvhSeXTpHq59fCV5+w+ZuvwFvzXTPVi8Pj+/X7KD+9/a2qkWuW5/Ne/7p7PXb2X1gfl+Am5+3UwhfZiPd5hZRsvrWqgMZPzVzcEgsa24Llgi6I1MqKqhlagIB6fnpvDGxoP9OhWu1+dn9b4qfCEBos7jJSHaRYTTQWaSu9tSz8q9lZz/x0/M3+oEFSirjR4cz7iMeD7YVtbPLWq3el9VcHRbb1uVX8WCf6wL9quF8nh9LFpb2OGgEAj8gxLcXDc9i1fWFVE6wMfz93XgfxMIDBK/BXijj7ffq+LdLpwORVayye6TQgL/4IT2+T7GZrTP3DMy3QT+z/eaUS1JGcPh6y/zStwNPPLxHtbur+bhD3d32ladx8tNT6/m0WV7+fvnB7jgT8spr2//cuYdqCYyIoJXkr5FviMHnXRYiSg+o33IJ/A/72znkkc+5bM95u5dZfWe4NWdrT4/n1ujbj7Z1V5m+zKB3+P18dKagmDdtLKhldTYSG6dk0vhoWbe3lRylDV8ec+uyOc/39rWIbCHenFNAV97YhWXPPIpS3eWo7WmrtlLgtv8HbOTY7os9SzfVcHNT69hd3lD8O94Igpk/OlxUVw2eQjrDlR3OoOp83iZ9+BSFuUV9lm7vD4/tz2Xxx/e3wmYs9Xe7HgOTLsQSK5C/XtTCT9dvIkvCtt/V9vsJTHG/M1vnzsSn1/z0tqCXmvPiSicwzlfBD4HxiqlipRStwEPAOcrpXYD51s/n/QCM3yGZvyREQ7S4sxwzdDAnxQTyQ2n59DQ0ka8O4KoCCeO0edy2VfmkpMSw7WnZfHZnkr2WOOuqxtb2Vlaz23PriVvfzV/vG4yi793Bg0tbXy4rZyX1hSw4O95rNhTyeTsJIbMvo6vND1AQZ3fzEESMgVBqE93V7K1uA6P18+M4cnUNHkpCRl+Wm9dyLTKOgA4HarTBWndaWhp46pHV/DZ7kpeWVfEva9u5ndLzDQQVY0tpMZFcf74wYwZHMejy/Yc9ZS8uKaZzUUdZ8vUWvPHD3Z1GoEU6pX1RSxckc9dL2/A79dsKqrhmRXtp/Gf7a4kNTaSZq+PW59Zy48XbTSBP7o98Ac6uktrPdz6zBrK6z0sXl9EUoyLBHcEZfUeWtv8vPZFUXBEUE/84rXN/OWjzgf4UKW1HhblFVLbdGz3BvD6/Dy6bA97rCkn0uOjuOxUM1XH4QfaN744yP6qJu57c2vH6cGPwuP18eB7O4JnFWCG6vYkgH9RUENDSxt7KxqpbGjhzN8tZfH6gz3e9tGUWwe89V0E/sDUy6FncoGMHyA7JYaclJgBMV3HkYRzVM/XtdaZWmuX1jpLa/201rpKa32u1nq09Xjinicfg+wuAj+0l3sC1wEE3HvRODIS3AyyrhUAuH5mDp/8ZB73XjSOyAgHz608gNaaCx9ezoUPL2fdgWoevn4KV0/LYnJWIlnJ0by3tZSHPtjF+9vK2FFaz4zhyZw2zHTkbSis4Vevb+GU+95nzgMfM+eBj4NBT2tN0aEmrpo6lP+76TS+Os30B+worQ+WogAS3BF4feY/8rScJPIre/af4Y0NB/mioIaFK/J53yovPP1ZPkt3llPV0EpqXCQOh+K7Z49kV1kDq/KPnDX/9zvb+fqTqzr0geRXNvLIR7u5ZeGaDqflza2+YJ9EQVUTKbGRvLWxmI1FNSz8LJ/739pGVUMLfr9mdf4hzh0/iA/uPptrT8vitQ0HKa71BP+OWcnRVNS34PH6eHdLCUt3VvDvTSWszT/E6bmpDEmKprS2hfe2lnL3yxs55w/LggfKI9ldVs8Lqwt48tN9tLR1fZe1RXmFzH7gI376yiYeX773qOsMtWJPJb9fspPHP9mLQ0FKbCQ5qTFMzk7iuZX7WR5yFvfS2kJy02JxKMX9b23r8TaeWbGfvy3dy8trzZlCbZOXs36/lHv+temowf+z3Wb7+ZVmSvLWNn+HNgG8tKaAG59a1e3Z2pEEznQ2FdV2KiUGptsOPfMJDfxg/j93dRDUWvPgezt4Z/OXO0utbmw1c35Zmlrb+q0j+YTt3D2ZdJXxA2QkunE5VYdgCpDgdvHPb8/kwWsnd1iulCI1Lopzxw1i6c5yiqqbKa9v4RuzcnjjzjO51MralFKcN34wn+yqoKK+hcsmm+VzRqUxZnAc0S4nXxTU8MG2MiYNTWDG8GQinIqnP8s3Vxk3e6lvaWPikAQunJgRLEvVe9o4ZWhisD3nTzBTPsREOjltWAoFh5qOWpPXWvPPVeY0+ZNdFXy+t5JbZg8jI8HNv/IKqWpoITXWHPAumpRJTKSTtzYWd1iH1+enubU9IG6wMsRlITXb7SXmjKiyoZW7Xv7Cet7C1Y+tZP6fTRmsztPG5da+2VJcxzar32J1/iG2ldRR2+xl9shUIiMcXDp5CFqboJHgNn02gQN6UXVTMKC/uKaA4loPM4YnMzjBTVmdhwPWFBwRDgePHCWLB3jGmsOpztPGp7tMqW1PeT2L8grZUVpHbZOX/3lnO6flJDMtJ4klW0qPqRSy1up3aGz1kRIbhdMaevarS8YT4VTcvHANefsPsbmolq3FdXxrznCunDqENflVaK15YXVBcB1dqW3y8tiyPQDBe1UsXl9ETZOXxeuL+Ofq9jJJ3v5D3PbsWqobW9lf2cj6gmqW7zaf2eP1s2xnRfB1AR6vjz+8v4sVe6o6HRCOZHNRLY0tbcGL1pq9PlbsrQpeLOjz6+B3IHTIcm2zt0OZdlhqDAeqOgf+0joPf1u6lzueX8/vl3Q9kWGbz9/tcNDv/D2Pbz6zNvjz/W9u49yHlvH4J3v7/BoLCfy9oLvAf9XUoXz7rBG4nJ1386hB8UzL6frC5cnZSRRVNwfrx1dPy+KUrMQOrzl3vBkJm5no5k/XTWb9r8/njJFpRDgdnDI0kTc3FlPV2Mo3z8jl4euncue8URRVN7PlYB0FVjYTCGzpIWce2SnRpMZG4nY5gtvISYlhRHosXp/mYBcXuNQ2e7n75Q1c/tfPuOHJ1WwvqeOmWcPw+TVen+bSyUOYnJ3IjtJ6KhtbSYszHdbRkU4umDCYdzaXdvjP8u3n8ph033vc+NQqCg81Bbf5ZsgBYltJLREOxV3njmbVvkPsLK3n5qfXsL2kjqZWH8t2mIAxa0QKidEuvjhQzV6rVPX53qpgIJ81wlxpHbhmAwg57Td9NwWHmlidfwil2odEzsxNJcMK/IWHmkmLi+Krpw1ldf4hqkNmwmxqbePV9UXBA2Ztk5dX1xdx9dShJMW4eHtTMQ0tbdyycC0/fWUT8x/+lHP/uIzaZi//ecUkrp6WRX5lY3C7rW3+owaJtfnVwckGQ/+2M4an8M5/nIXToVi2s4K3NhUT6XRw+ZShjEqPo87TRlldC/e9tZW/fryn2/U/umwP9S1tXDBhMOsLqqlubOWFNQVMzkpk7ph0fv36Fm5euIY6j5fXNxzkox3l3LxwDZf95TOufnQlG4tqmDncnJm+t7UUMJOjBbLwxeuLqGxoISrCwfOrD3TZhrz9hzj7waX8/fP9aK1Zd+AQl/31M577fD/ldR6GJpm/3beeXcvXnljF7rJ68ivNhHXQHvhb2/w0tfo6/N/NSYmhttlLVUMLTy7fFzyjDPwNxmXE88TyfV3envM3b27l5oWdJzncW9FA3oFqNh+sJb+yEY/XxzubS4h3u3jg3R28u6W003vqPV5e/+JgrwyjPpwE/l4wYUgCCe6IDrV8gItPyeRn88cd8/oCWfeivEKUMl+0w83MTSEz0c235uQS4XSQEts++mdydmKwozYwydz5EwbjdCje3VISrG8G7kUwKKE9OKTERpGdEsOYwfGMGWzGsuekxDAy3Tz/MGQIZnFNM61tfj7ZVcFrXxwk2uWkrM5DRoKbn84fy7iMeFJjI5mWk8zYjAT2VTTS2uYnNa69rVdMGUptszfYiay1Zv2BarKSo1mxp4o/Wxn0+MwEPtpezu3/yONfeYVsK65jZHoc18/MwelQ3PH8OraV1PEf54622mlKTFnJMUwcksB7W0vx+TVREQ5W7K3kw+1lDE+NCQ67TYx2Mcoau58QLPWY/fPq+oPUNHm5coq5mC7e+lsPToiisqGF/KpGslOimT8xE59f8/amYp5dkU9ts5dnV+7nR4s2ct9bW9HadBp6vH6+fdYILpqUyZKtpdz27FqKa5t57MZp3H/5RBLcLm6bk8uEIQlcMHEwSsG7W0pobGnj3D8u46pHV3Zbj29p87GhqIbrZ2YzNCmaoUkdbyoS73ZxytBEVu2rYtnOcmbmmgPjiODft4zWNj/rD1R3WWbZU97A05/lc820LL47byR+Db9+Ywt7yhu4cdYwnrjpNO69aBzLd1XwxoZiviioIS0uks0Ha8lMcnPNaVkoYIF1B7ySWg+Dre9f3v5qtNY89Wk+k7MSue3MXD7eUd5pBFt+ZSPf/nseJbUe/t8bW/nuP9fxi1fNzDC7yxqoaGhhSnYSWcnRJMdEEhnh4B+rDrDloMn2Rw8y06bXe7z8a50pVQU6dwPfd4DnVxfw3+9s54anVlHV0MIua6K7ey4YS5tfs2xnOd9+Lo8/hwzG2HywlvUFNbT5/Ny7eBP/+Hy/9R0qCl7z887mEpbtLKe+pY1Hvj6VwQlRvLGhcx/H1uI67np5Q/AspTfZ4w5cYTY4wc2m+y7stfVNGmICf96BakakxRIT2fnPFBXhZOW9nW8sA+aMAWDUoDgyrH6G5NhIZo9I5d0tpcS7O2a0qVY5wOfXpMVF8tsrJwGQkxKL2+Vg1KA4pmYnMW9sOv/7znZy02JQSvGd5/L48QVjqWlqJdLp4B+3nU5khAOtNUopHrpuMo0tPpwOxfiQg1eg1ANw5ug0BsVH8cC725k9MpV6jylD3XPhWP7y8R4Wry9CKfh/l07gxqdW8fGOctYX1KAwpa30+CjOGTeID7aVccrQRL7/lVE8tmwPn1rlhJxUE/hXhpw9vbimgH0Vjfz60o43xpmWk8Se8obgqJ5B8VHMHZMe7BD9wTmjeG9rKdOHJeN0KAYnuvFrU2I4b8JgJg1NYGhSNP/vza1oDYeavKzaV0WEQ/HPVQVkJLh5cU0hp+emMGFIAnfMG8neigZW5x/i9rNHcNEpZijuLWcMD7ZpULybGcNTeGF1ASU15uyiutHLlX9bwcf3zOuQqba2+dlYaGrms0akcusZubgiOl+QePqIFJ76NB+fX3PtaWb010jroPdv67PWt7Sxs7Q+eAVzwP1vbSUm0snPLhpHckwkyTEu3t5UwqlZiVx26hDcLie3zx3BP1cd4L0tpeworeeOeSM5Z9wgRg2KI97t4v7LJxIT6SQ20kljq49LThnCv/IKWbv/EEOTo8mvbOShayczMzeFxz7Zy0trC/nR+WMAkxj8/NVNKOC9u+ayZEspj3y0m2avj6QYF/mVjVTUtTB3dBQvLZhFTGQEv/33NhavK6KivgW3y8G8sek8u3I/D72/i2dX7ifa5WRiyOfMSTGl2cXri4hwKIprmvnla1uId0eQFme+b2lxUTz43k6KqpvZWFTDD84ZhcOhKDzURGubnx2l9bycV4jL4WBqTjKvrT/I3DHp1DZ7eWtjMZmJbtLiIpkzMpWLJmXy4poCGlragkPDAXZYAX98F4nf8ZKM/wSUGONiWKrJOsYP6X5uHaUUqospGAJlizNDZh0FmD8pg/zKRj7aXkZyjCt4AHA6VLD8khIbyaShiUwamkhkhINXvzeH288eicOheOTrUxmZHse3ns3jO8/l0ebXfLq7gs0HaxmXGU+kddvKQJsmDklkpnXVaOjZUGjG73I6ePj6KeRXNvLL1zYHZ8QcmxHPRZMy0BpGpccxe2Qqm+67kL/dMI2K+hbK61sYn2nWeePpOSgFP50/lsgIByPS4mj2mtP3BLeLidaBNDbSyY2nm+sbvjY9m2/NGd5h/0y1Sm+BYKqU4i/XT2VEeizDU2MYkR7HEzdN55eXjAfMpF5gasnZydEopbhs8hBcDgc5KTEsXlfE+gPVfPusEVwxZQh/eH8XB2uauXVOLmBKbYtun83G31zAvUc4M7z/8ol4vD5ezivkiilDeGnBLA41tfL4J+2dvm0+P2c/uJQbnjS3zpw+LJmckDOaULNGpAaz+XljzcWRmQluol1OVudXBWf1yDvQsc6/u6yeT3dXcsdXRpEWZ5KF+6+YxG8um8Di751BdKQzuN/OGp3OZ3sq8fk103KSmZqTHPy+xUZFoJQi1xraPD4zntNHpLBkSynPrjCBeP6kDLJTYpg7Op2X1xawu6ye/3p7G6+uP8iqfYf44bmjyU2L5XvzRrLsJ/N45tYZXHpqJrvK6qlvaSM9Poqs5BhSYiO5ZfZwGlt9vLullNkjUhmWasqWr284yFmj09h83wXBQRFgkgUw80qdkpXI9TNyWLqznE1FtYwZHIfDoTh/wiCKqptxOhQV9S1sKDL9UNXWCKzXvziI1mZo9GV//YziWg83zRrGJadksqO0nqU7K7jmtGwinA4uOTWTljZzhvDdf6wL9m/tKK0nOcbVoVzXWyTjP0FNGprIgaomJmR2H/i7k5Ucw++/eipzx3S84vmCiYP59RtbyDtQzamH9RkMindTVtfSIRsHOmR8CW4Xr985h4Ur8snbf4h4t4v3t5XicjqCHc/dGZZqzh48Xn9wmGvAGSPT+M7cETyxfF/wmojRg+K45NRM/rHqQLB/Iy4qgq9Y2VZlQwsTMs3yeWMHsfaX5wXXOyYjnp1l9cFT9kA2Ny4zgUlDE3n7B2cyLiO+00Hz7DHpjEiLDR5QwByEX/3eGTRa/xnPHN1+MA29ViPQX3LPBWNYMHcEH24r46eLNwFwzrhBTMtJwulQ7C1v4PwJ7Tfwgc59Q4cbn5nAM7fO5LFle/j5RePJSHRz5ZShLPwsnxtm5pCdEsO6A9WU1HqYNSKFcRkJpMZ1HyymD0vGocyBK1DecjgUI9Jj2Vpcx9jB8dQ2e1m7v5qbZw8Pvu8VKwO+5rT2q8IDneeHO3tMGi+uMZ28U3OSunxNblocWw7WMS4jgYlDErnsr5/x780lXDV1aPB+GDeensOCf6zjyr+tCP4NhiS6+frp7RcoDk5wMzjBzd7y9hp+aLCcnJ3E3781k6QYkwR8ao0qqmnycs64QUQc1gcXZ92Vr6qxlZnDU5g7xpwh7Cyr55sjzf64cGIGL64p5Gfzx/L7JTt5f2sZMZHtd+17fYPpj/r1pRN4f2spP7lwLNOHp9Dc6iMuKoJhqbHBqTROy0lmcEJU8Mzya/lVfGXsIHaU1jMuI6HL5O54ScZ/ggrU+b9M4Ae4bkZ2sMwTECgbQHt9PyBQZw3NxrsSHenkzq+M4plbZ3LxKZl4vP5Oo4G64nQoxgyO73YbF0/KRGt4YXUBKbGRpMZFMWN4CpeckslVU9snqnM5HVxzWhZOh+pwUAo9mIyxglmglJWbFku8OyJ4sJs0NLHTf3aAIUnRfHzPvGC9OyApJjLYWRiqQ+C39megv+XCSRlEOh3EuyOYlpNEhNPBH6+bwut3zgmOsjkWpw1L5qlbZgT/pj86fwwRDsV1//c524rr+HhnOS6n4smbp3Pf5ROPuK54t4srpw7lxlnDOgSVQD/O+Mx4ZuSmdBhp4/NrXv/iIPPGpnc6cHdl9sg0HApGpMeSFNP1d2pCZgLRLiejBsUxYUgC3znL1P2vntb+9z5n3CAyEtz4tOavN0zlggmD+c8rJhEV4ey0vtDRc4MOy5Lnjknn1Kwk64LL9u/+2YclRwGBA/nM3BRmDE8h3joQBb7DZ49J59U7zuA7Z41g1ohU3t9WSpHVd6aUGWE2KD6K287M5eXbZzPd+n8XHenk+pk5zB6ZGpwXzOFQPHrjNJ646TQinQ5W7qnE79fsKqvv1G/YWyTjP0FdNCmDvP2HmD68d29ZcNGkDNbkHwp+sQPS462+gG7+k3YlUMYBmDT06AeocRnxbCqq7dAR3f7+RJJjXFQ3eYPrdToUf7txWqfX3nXeaC4+JaPL9YDJ+KFjMH7tjjm9fsqcGhuJy6nw+nTwIBOQGO3itrNycTlUh4NMb2Vv2SkxLPrubG57No9vPrOGmEinCVDuI589BPzxuimdlo2wSi/jMhOIinDw1sZiyuo8tPk1Dy7ZQVldC/df3rNpwhOjXXx1WhbDDxvKHOrWOcO59NTMYInoxxeM4azRaZwxsv2OeBFOB09/czpam+/Ikc4sQwP/kf7WgbPK7JToTkOtA4alxrCxqIbpw1KIjHBw9ljT1zM2wxwclVLBUXnnjR/EfW9tY8Ve0680JTuJLwpqjpoMhQqUmqYNS2LFnioKq5toavV1OPvsTRL4T1DDUmN56pYZvb7eiyZl8rslOzp0ZoGp/zsUwTp9T6TERjIuI5495Q3BTOhIbjh9GBmJ0V1ma06HqQu/ubE4ODNmd9wuJ6dmJXX7+wmZCSjVnsECwZJGb3I4FIPi3RTXNndZS/8yI7qOxcQhiTx1y3SuenQF5fWaG08fdlzrC+yjcRnxxFvXMmwqquXpz/bxRUEN3z4zl/PGDz7SKjo4/DqVw7ldzg4JiMvp6HA3vIBAH83RZKfEBAcpDIp3d/s6t8vJyPRYzh0/uNsD8ddmZDMqPS442uf6GTnsLmtgXEbnBCdQ/guMbJs1IpUvCmqYdAyBP2DOyDQe+mBXcCh3V9vrDRL4bSYj0c2aX54XPHUNOHtMerenvUdyw+k5bCuuC97A5kimZCd1GC9/uLljehb4jyY7JYbX75jT6YrpcBiUEIXW+pgOmL1p0tBEfnLhWH63ZCfnTeh5UO7KeeMHc99lEzhzVBpen8ahYE1+FesOVHPbmSO496LwHsiOl8vpICs5msJDTd2eDQa8/YOzcDm7P/s6Y2QaZ4xsPwidOTqN9+6e2+VrR6bHMSg+ivL6FkYPigsOgz6WjD+43VEm8D/2yV6UokcJ1Zchgd+GEnpYDuiJ0M6/43X++MGcO24Q54w7vgAG7UNaw+2SUzKpDrlna39YMHck15yWfdRgdzRul5NvWiOOIpwm6Ly8thCvTzM7pPxyIstNi6Wp1XfUfpToyKMnKj2llGLOqDRe++Ig2SkxnD8hg7vOa+KsMZ3PXo5mclaiuWfHoSbOHJXWq+0MJYFfnDASY1w8/c3eL2+F07etDsn+drxBvyuThpqrrSMciunDTojbYx/VgrkjOt1Bri+cMTKV1744SFZyNHFREdx13pgvtZ4Ip4Ol98zr3cZ1tZ2wb0EIcVI6NSuRV9YVMTk7KTi88kQXWp7pS2eOTsPpUB36lU5kJ8dfUwjR5wI16tkjTo4yT3/KTIzm7R+c2e0ooRONBH4hRJdOGZrId88e2eFiKdG9vhhM0Fsk8AshuhThdJzwI3nElyNX7gohhM1I4BdCCJuRwC+EEDYjgV8IIWxGAr8QQtiMBH4hhLAZCfxCCGEzEviFEMJmlNa6v9twVEqpCuDAl3x7GlDZi80ZKGS/dCb7pGuyXzo7WfbJMK11p/nWT4rAfzyUUnla6+n93Y4TjeyXzmSfdE32S2cn+z6RUo8QQtiMBH4hhLAZOwT+J/q7ASco2S+dyT7pmuyXzk7qfTLga/xCCCE6skPGL4QQIoQEfiGEsJkBHfiVUvOVUjuVUnuUUvf2d3v6i1Jqv1Jqs1Jqg1Iqz1qWopT6QCm123o8Oe6mfRyUUguVUuVKqS0hy7rdD0qpn1vfnZ1KqQv7p9Xh1c0+uU8pddD6vmxQSl0c8js77JNspdRSpdR2pdRWpdQPreUD5rsyYAO/UsoJ/A24CJgAfF0pNaF/W9WvvqK1nhIy9vhe4COt9WjgI+vnge5ZYP5hy7rcD9Z35XpgovWeR63v1EDzLJ33CcCfrO/LFK31O2CrfdIG/FhrPR6YBdxpffYB810ZsIEfmAns0Vrv01q3Ai8BV/Rzm04kVwDPWc+fA67sv6b0Da31cuDQYYu72w9XAC9prVu01vnAHsx3akDpZp90xy77pERrvd56Xg9sB4YygL4rAznwDwUKQ34uspbZkQbeV0qtU0otsJYN1lqXgPmiA4P6rXX9q7v9YPfvz/eVUpusUlCgpGG7faKUGg5MBVYzgL4rAznwqy6W2XXs6hyt9TRM2etOpdTc/m7QScDO35/HgJHAFKAEeMhabqt9opSKAxYDd2mt64700i6WndD7ZSAH/iIgO+TnLKC4n9rSr7TWxdZjOfAa5jS0TCmVCWA9lvdfC/tVd/vBtt8frXWZ1tqntfYDT9JetrDNPlFKuTBB/3mt9avW4gHzXRnIgX8tMFoplauUisR0vrzZz23qc0qpWKVUfOA5cAGwBbMvbrFedgvwRv+0sN91tx/eBK5XSkUppXKB0cCafmhfnwsEN8tVmO8L2GSfKKUU8DSwXWv9x5BfDZjvSkR/NyBctNZtSqnvA+8BTmCh1nprPzerPwwGXjPfZSKAF7TWS5RSa4FFSqnbgALg2n5sY59QSr0IzAPSlFJFwG+AB+hiP2ittyqlFgHbMKM87tRa+/ql4WHUzT6Zp5SagilX7AduB/vsE2AOcBOwWSm1wVr2CwbQd0WmbBBCCJsZyKUeIYQQXZDAL4QQNiOBXwghbEYCvxBC2IwEfiGEsBkJ/MIWlFIrrcfhSqkbenndv+hqW0KcqGQ4p7AVpdQ84B6t9aXH8B7nkcZlK6UatNZxvdA8IfqEZPzCFpRSDdbTB4CzrHnm71ZKOZVSDyql1lqTkt1uvX6eNSf7C8Bma9nr1kR3WwOT3SmlHgCirfU9H7otZTyolNqizP0Qvhay7mVKqVeUUjuUUs9bV4uilHpAKbXNassf+nIfCfsYsFfuCtGNewnJ+K0AXqu1nqGUigJWKKXet147E5hkTbUL8C2t9SGlVDSwVim1WGt9r1Lq+1rrKV1s62rMRGeTgTTrPcut303FzN9eDKwA5iiltmGmSBintdZKqaTe/ehCGJLxC7u7ALjZujR/NZCKmWsFYE1I0Af4D6XURmAVZlKu0RzZmcCL1oRnZcAnwIyQdRdZE6FtAIYDdYAHeEopdTXQdJyfTYguSeAXdqeAH4TcbSpXax3I+BuDLzJ9A+cBs7XWk4EvAHcP1t2dlpDnPiBCa92GOctYjLnJx5Jj+BxC9JgEfmE39UB8yM/vAd+zpuFFKTXGmsX0cIlAtda6SSk1DnNLvgBv4P2HWQ58zepHSAfmcoRZG6353xOtWx3ehSkTCdHrpMYv7GYT0GaVbJ4F/owps6y3Olgr6Po2lEuA7yqlNgE7MeWegCeATUqp9VrrG0OWvwbMBjZiZrr8qda61DpwdCUeeEMp5cacLdz9pT6hEEchwzmFEMJmpNQjhBA2I4FfCCFsRgK/EELYjAR+IYSwGQn8QghhMxL4hRDCZiTwCyGEzfx/WOZS9pAecysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_results[0]['training_loss'], label=\"train\")\n",
    "plt.plot(training_results[0]['validation_loss'], label=\"val\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()\n",
    "#plt.title('training loss iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94fdad87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 4.1579, 'rouge2': 0.0486, 'rougeL': 4.0191, 'rougeLsum': 4.0207}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d44fd335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 11:22:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-PCIE-40GB      Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    39W / 250W |   8855MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  A100-PCIE-40GB      Off  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   68C    P0   233W / 250W |  40137MiB / 40536MiB |     92%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  A100-PCIE-40GB      Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  A100-PCIE-40GB      Off  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    37W / 250W |    586MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  A100-PCIE-40GB      Off  | 00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    69W / 250W |   5179MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    914655      C   .../obj_detection/bin/python     5979MiB |\n",
      "|    0   N/A  N/A   1864849      C   ...onda3/envs/sb3/bin/python     1773MiB |\n",
      "|    0   N/A  N/A   2026001      C   python                            603MiB |\n",
      "|    0   N/A  N/A   2839719      C   python                            497MiB |\n",
      "|    1   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    1   N/A  N/A   3404078      C   python                          39551MiB |\n",
      "|    2   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    3   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    4   N/A  N/A    914655      C   .../obj_detection/bin/python      583MiB |\n",
      "|    4   N/A  N/A   1864849      C   ...onda3/envs/sb3/bin/python     4593MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6948a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('philschmid-bart-base-samsum.pickle', 'wb') as f:\n",
    "    pickle.dump(training_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033ec07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
